{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b839957",
   "metadata": {},
   "source": [
    "# Hybrid vs Individual Swarm Intelligence IDS Comparison\n",
    "This notebook compares performance of individual swarm algorithms (ACO, PSO, ABC, MWPA) against the deep hybrid method for feature selection on NSL-KDD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a4121",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe265a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install pyswarms scikit-learn pandas numpy matplotlib seaborn scipy -q\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "url = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTrain+.txt\"\n",
    "cols_url = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDFeatureNames.txt\"\n",
    "features = pd.read_csv(cols_url, sep=\":\", header=None)[0].tolist() + ['target']\n",
    "data = pd.read_csv(url, names=features)\n",
    "\n",
    "# Preprocess\n",
    "le = LabelEncoder()\n",
    "for col in data.select_dtypes(include='object').columns:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "X = data.drop('target', axis=1).values\n",
    "y = (data['target'] != 0).astype(int).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faba935a",
   "metadata": {},
   "source": [
    "## 2. Define Swarm Feature Selection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# ACO, PSO, ABC, MWPA functions as defined previously...\n",
    "# [Insert your previously defined functions here]\n",
    "# For brevity, assume they've been imported or defined in the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4f7ffe",
   "metadata": {},
   "source": [
    "## 3. Feature Selection and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2031bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "methods = {\n",
    "    'ACO': aco_feature_selection,\n",
    "    'PSO': pso_feature_selection,\n",
    "    'ABC': abc_feature_selection,\n",
    "    'MWPA': mwpa_feature_selection,\n",
    "    'Hybrid': deep_hybrid_selection\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, func in methods.items():\n",
    "    start = time.time()\n",
    "    feats = func(X_train, y_train)\n",
    "    duration = time.time() - start\n",
    "    X_tr = X_train[:, feats]\n",
    "    X_te = X_test[:, feats]\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    clf.fit(X_tr, y_train)\n",
    "    y_pred = clf.predict(X_te)\n",
    "    y_prob = clf.predict_proba(X_te)[:,1]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    fpr = fp / (fp + tn)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    results[name] = {'accuracy': acc, 'fpr': fpr, 'auc': auc, 'time': duration, 'n_features': len(feats)}\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a22289f",
   "metadata": {},
   "source": [
    "## 4. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e7177",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(results).T\n",
    "df = df[['accuracy','fpr','auc','time','n_features']]\n",
    "display(df)\n",
    "\n",
    "# Bar plots\n",
    "df[['accuracy','auc']].plot(kind='bar', title='Accuracy and AUC Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.show()\n",
    "\n",
    "df['fpr'].plot(kind='bar', title='False Positive Rate Comparison')\n",
    "plt.ylabel('FPR')\n",
    "plt.show()\n",
    "\n",
    "df['time'].plot(kind='bar', title='Computation Time Comparison')\n",
    "plt.ylabel('Seconds')\n",
    "plt.show()\n",
    "\n",
    "df['n_features'].plot(kind='bar', title='Number of Selected Features')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
