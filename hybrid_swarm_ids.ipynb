{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62e0f418",
   "metadata": {},
   "source": [
    "# Hybrid Swarm Intelligence Intrusion Detection System (IDS)\n",
    "\n",
    "This notebook implements a hybrid swarm intelligence model integrating ACO, PSO, ABC, and MWPA for intrusion detection on the NSL-KDD dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74831499",
   "metadata": {},
   "source": [
    "## 1. Define Objectives\n",
    "\n",
    "- Develop and evaluate a hybrid swarm intelligence model integrating ACO, PSO, ABC, and MWPA for intrusion detection.\n",
    "- Key Metrics: Classification accuracy, False positive rate (FPR), Convergence speed, Computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4e54d",
   "metadata": {},
   "source": [
    "## 2. Data Acquisition\n",
    "\n",
    "Use the Kaggle-hosted NSL-KDD dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af9d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Kaggle API and download NSL-KDD\n",
    "!pip install kaggle\n",
    "import os\n",
    "# Ensure your Kaggle API token is in ~/.kaggle/kaggle.json\n",
    "!kaggle datasets download -d hassansubhani/nslkdd\n",
    "!unzip -q nslkdd.zip -d data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0695c29a",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Handle missing values, normalize features, encode categorical variables, split into train/val/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b986190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load data\n",
    "columns = open('data/KDDTrain+.txt').readline().strip().split(',')  # adjust if header exists\n",
    "train = pd.read_csv('data/KDDTrain+.txt', names=columns)\n",
    "test = pd.read_csv('data/KDDTest+.txt', names=columns)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train['label'] = le.fit_transform(train['label'])\n",
    "test['label'] = le.transform(test['label'])\n",
    "\n",
    "# Select features and normalize\n",
    "X = train.drop('label', axis=1)\n",
    "y = train['label']\n",
    "X_test = test.drop('label', axis=1)\n",
    "y_test = test['label']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train/Validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0bb3f1",
   "metadata": {},
   "source": [
    "## 4. Feature Selection with Hybrid Swarm Intelligence\n",
    "\n",
    "Implement hybrid algorithm combining ACO, PSO, ABC, and MWPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b276ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder: import or implement hybrid SI algorithms\n",
    "# For demonstration, we'll define a stub that returns all features\n",
    "def hybrid_feature_selection(X, y):\n",
    "    # TODO: integrate ACO, PSO, ABC, MWPA\n",
    "    return list(range(X.shape[1]))\n",
    "\n",
    "selected_features = hybrid_feature_selection(X_train, y_train)\n",
    "X_train_sel = X_train[:, selected_features]\n",
    "X_val_sel = X_val[:, selected_features]\n",
    "X_test_sel = X_test_scaled[:, selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabd3525",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "Train classifiers and optimize hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83afacfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define classifier and hyperparameter grid\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "param_grid = {'n_estimators': [50, 100], 'max_depth': [None, 10]}\n",
    "\n",
    "grid = GridSearchCV(clf, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid.fit(X_train_sel, y_train)\n",
    "\n",
    "best_clf = grid.best_estimator_\n",
    "print(\"Best parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8830b854",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "Evaluate accuracy, precision, recall, F1-score, ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "y_pred = best_clf.predict(X_test_sel)\n",
    "y_proba = best_clf.predict_proba(X_test_sel)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46f3bad",
   "metadata": {},
   "source": [
    "## 7. Benchmark Function Analysis\n",
    "\n",
    "Evaluate hybrid algorithm on benchmark functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca7225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import rosen, rastrigin\n",
    "\n",
    "# Define benchmark functions\n",
    "def evaluate_benchmarks(funcs, dim=30):\n",
    "    results = {}\n",
    "    for name, func in funcs.items():\n",
    "        # Placeholder: apply hybrid SI to minimize func\n",
    "        results[name] = func(np.zeros(dim))\n",
    "    return results\n",
    "\n",
    "funcs = {'Rosenbrock': rosen, 'Rastrigin': rastrigin}\n",
    "bench_results = evaluate_benchmarks(funcs)\n",
    "print(bench_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcaa55e",
   "metadata": {},
   "source": [
    "## 8. Component-wise Analysis\n",
    "\n",
    "Study adaptive inertia weights, MWPA behavior, and crossover strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89afa127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add detailed analysis of individual components' impact\n",
    "# This section will include plots and metrics for each sub-algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a144b2a",
   "metadata": {},
   "source": [
    "## 9. Presentation and Demonstration\n",
    "\n",
    "Visualize results with Matplotlib and Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44160f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Placeholder: Example plot\n",
    "plt.figure()\n",
    "plt.plot([0,1,2,3], [0.8,0.85,0.9,0.88])\n",
    "plt.title('Convergence Curve')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e2fa99",
   "metadata": {},
   "source": [
    "## 10. Tools and Libraries\n",
    "\n",
    "- Pandas\n",
    "- NumPy\n",
    "- Scikit-learn\n",
    "- Matplotlib\n",
    "- Seaborn\n",
    "- PySwarm (for PSO)\n",
    "- SciPy\n",
    "- PyTorch (if using neural networks)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
