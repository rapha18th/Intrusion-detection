{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 394223,
     "sourceType": "datasetVersion",
     "datasetId": 174616
    }
   ],
   "dockerImageVersionId": 31012,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "id": "310c2579",
   "cell_type": "markdown",
   "source": "## Deep Hybrid Swarm Intelligence IDS\n\nThis notebook implements an advanced hybrid swarm intelligence feature selection algorithm that integrates **Ant Colony Optimization (ACO)**, **Particle Swarm Optimization (PSO)**, **Artificial Bee Colony (ABC)**, and **Modified Wolf Predation Algorithm (MWPA)** within a single unified loop.",
   "metadata": {}
  },
  {
   "id": "68422d48",
   "cell_type": "markdown",
   "source": "### 1. Setup & Data Acquisition\n\nInstall dependencies and load the NSL-KDD dataset.",
   "metadata": {}
  },
  {
   "id": "39292f52",
   "cell_type": "code",
   "source": "\n!pip install pyswarms scikit-learn pandas numpy matplotlib seaborn scipy -q\n\nimport pandas as pd\nimport requests\nfrom io import StringIO\n\n# New URLs based on your GitHub repo\ndata_url = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTrain+.txt\"\nfeatures_url = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/Field Names.csv\"\n\n# Fetch feature names\nfeatures_response = requests.get(features_url)\nfeatures_response.raise_for_status()  # Check for request errors\nfeatures = pd.read_csv(StringIO(features_response.text), header=None)[0].tolist() + ['target']\n\n# Fetch dataset\ndata_response = requests.get(data_url)\ndata_response.raise_for_status()  # Check for request errors\ndata = pd.read_csv(StringIO(data_response.text), names=features)\n\n# Show sample\ndata.head()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-04-28T16:44:11.897096Z",
     "iopub.execute_input": "2025-04-28T16:44:11.897318Z",
     "iopub.status.idle": "2025-04-28T16:44:22.605163Z",
     "shell.execute_reply.started": "2025-04-28T16:44:11.897297Z",
     "shell.execute_reply": "2025-04-28T16:44:22.603804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h",
     "output_type": "stream"
    },
    {
     "execution_count": 1,
     "output_type": "execute_result",
     "data": {
      "text/plain": "  duration protocol_type service  flag  src_bytes  dst_bytes  land  \\\n0      tcp      ftp_data      SF   491          0          0     0   \n0      udp         other      SF   146          0          0     0   \n0      tcp       private      S0     0          0          0     0   \n0      tcp          http      SF   232       8153          0     0   \n0      tcp          http      SF   199        420          0     0   \n\n   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n0               0       0    0  ...                0.17   \n0               0       0    0  ...                0.00   \n0               0       0    0  ...                0.10   \n0               0       0    0  ...                1.00   \n0               0       0    0  ...                1.00   \n\n   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n0                    0.03                    0.17   \n0                    0.60                    0.88   \n0                    0.05                    0.00   \n0                    0.00                    0.03   \n0                    0.00                    0.00   \n\n   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n0                         0.00                         0.00   \n0                         0.00                         0.00   \n0                         0.00                         1.00   \n0                         0.04                         0.03   \n0                         0.00                         0.00   \n\n   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n0                  0.00                      0.05                  0.00   \n0                  0.00                      0.00                  0.00   \n0                  1.00                      0.00                  0.00   \n0                  0.01                      0.00                  0.01   \n0                  0.00                      0.00                  0.00   \n\n   dst_host_srv_rerror_rate  target  \n0                    normal      20  \n0                    normal      15  \n0                   neptune      19  \n0                    normal      21  \n0                    normal      21  \n\n[5 rows x 42 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n      <th>protocol_type</th>\n      <th>service</th>\n      <th>flag</th>\n      <th>src_bytes</th>\n      <th>dst_bytes</th>\n      <th>land</th>\n      <th>wrong_fragment</th>\n      <th>urgent</th>\n      <th>hot</th>\n      <th>...</th>\n      <th>dst_host_srv_count</th>\n      <th>dst_host_same_srv_rate</th>\n      <th>dst_host_diff_srv_rate</th>\n      <th>dst_host_same_src_port_rate</th>\n      <th>dst_host_srv_diff_host_rate</th>\n      <th>dst_host_serror_rate</th>\n      <th>dst_host_srv_serror_rate</th>\n      <th>dst_host_rerror_rate</th>\n      <th>dst_host_srv_rerror_rate</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tcp</td>\n      <td>ftp_data</td>\n      <td>SF</td>\n      <td>491</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.17</td>\n      <td>0.03</td>\n      <td>0.17</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.05</td>\n      <td>0.00</td>\n      <td>normal</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>udp</td>\n      <td>other</td>\n      <td>SF</td>\n      <td>146</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.60</td>\n      <td>0.88</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>normal</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>tcp</td>\n      <td>private</td>\n      <td>S0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.10</td>\n      <td>0.05</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>neptune</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>tcp</td>\n      <td>http</td>\n      <td>SF</td>\n      <td>232</td>\n      <td>8153</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.03</td>\n      <td>0.04</td>\n      <td>0.03</td>\n      <td>0.01</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>normal</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>tcp</td>\n      <td>http</td>\n      <td>SF</td>\n      <td>199</td>\n      <td>420</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>normal</td>\n      <td>21</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 42 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 1
  },
  {
   "id": "26bf7448",
   "cell_type": "markdown",
   "source": "### 2. Preprocessing",
   "metadata": {}
  },
  {
   "id": "013a1319",
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\n# Encode and normalize\nle = LabelEncoder()\nfor col in data.select_dtypes(include='object').columns:\n    data[col] = le.fit_transform(data[col])\nX = data.drop('target', axis=1).values\ny = (data['target'] != 0).astype(int).values  # binary\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-04-28T16:46:20.757353Z",
     "iopub.execute_input": "2025-04-28T16:46:20.757732Z",
     "iopub.status.idle": "2025-04-28T16:46:22.990586Z",
     "shell.execute_reply.started": "2025-04-28T16:46:20.757706Z",
     "shell.execute_reply": "2025-04-28T16:46:22.989354Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "id": "9002f1f2-97cb-4edf-ba38-492dd2bb9c13",
   "cell_type": "markdown",
   "source": "### Individual selection\n",
   "metadata": {}
  },
  {
   "id": "f84fe64a-6190-4d98-b73f-f82a9c873c16",
   "cell_type": "code",
   "source": "import numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ndef _binarize(position):\n    \"\"\"Sigmoid threshold at 0.5\"\"\"\n    return 1/(1+np.exp(-10*(position-0.5))) > 0.5\n\ndef _fitness(X, y, mask):\n    sel = _binarize(mask)\n    if not sel.any():\n        return 1.0\n    return 1 - cross_val_score(\n        RandomForestClassifier(n_estimators=30, random_state=42),\n        X[:, sel], y, cv=3\n    ).mean()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-04-28T16:46:28.315022Z",
     "iopub.execute_input": "2025-04-28T16:46:28.315554Z",
     "iopub.status.idle": "2025-04-28T16:46:28.870903Z",
     "shell.execute_reply.started": "2025-04-28T16:46:28.315514Z",
     "shell.execute_reply": "2025-04-28T16:46:28.869807Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "id": "cc97da02-40ca-48bb-a389-5eb0a8fd605e",
   "cell_type": "markdown",
   "source": "### Ant colony optimization",
   "metadata": {}
  },
  {
   "id": "ee3548a6-f085-482a-bece-ef6d1a3c6477",
   "cell_type": "code",
   "source": "def aco_feature_selection(X, y, pop_size=30, iters=50, evap_rate=0.1):\n    n_feat = X.shape[1]\n    # pheromone trail\n    pher = np.ones(n_feat)\n    best_mask = None\n    best_fit = np.inf\n\n    for t in range(iters):\n        ants = []\n        fits = []\n        # build ant solutions\n        for _ in range(pop_size):\n            prob = pher / pher.sum()\n            # sample each feature inclusion independently\n            position = (np.random.rand(n_feat) < prob).astype(float)\n            ants.append(position)\n            fits.append(_fitness(X, y, position))\n        fits = np.array(fits)\n\n        # update global best\n        idx = np.argmin(fits)\n        if fits[idx] < best_fit:\n            best_fit = fits[idx]\n            best_mask = ants[idx].copy()\n\n        # pheromone evaporation\n        pher *= (1 - evap_rate)\n        # deposit: only best ant reinforces\n        pher += evap_rate * best_mask\n\n    return np.where(_binarize(best_mask))[0]",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-04-28T16:46:37.481302Z",
     "iopub.execute_input": "2025-04-28T16:46:37.481804Z",
     "iopub.status.idle": "2025-04-28T16:46:37.489965Z",
     "shell.execute_reply.started": "2025-04-28T16:46:37.481765Z",
     "shell.execute_reply": "2025-04-28T16:46:37.489032Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "id": "af280f79-5609-4cbd-ac53-ebef4cde00fe",
   "cell_type": "markdown",
   "source": "#### Particle Swarm Optimization",
   "metadata": {}
  },
  {
   "id": "854e31ea-0771-4d50-83eb-a40924d663ba",
   "cell_type": "code",
   "source": "def pso_feature_selection(X, y, pop_size=30, iters=50, w=0.9, c1=1.5, c2=1.5):\n    n_feat = X.shape[1]\n    # positions and velocities\n    pos = np.random.rand(pop_size, n_feat)\n    vel = np.zeros_like(pos)\n    # personal and global bests\n    pbest = pos.copy()\n    pfit = np.array([_fitness(X, y, p) for p in pos])\n    gbest = pbest[np.argmin(pfit)]\n    gfit = pfit.min()\n\n    for t in range(iters):\n        for i in range(pop_size):\n            r1, r2 = np.random.rand(n_feat), np.random.rand(n_feat)\n            vel[i] = (\n                w*vel[i]\n                + c1*r1*(pbest[i] - pos[i])\n                + c2*r2*(gbest    - pos[i])\n            )\n            pos[i] += vel[i]\n            fit_i = _fitness(X, y, pos[i])\n            # update personal best\n            if fit_i < pfit[i]:\n                pfit[i] = fit_i\n                pbest[i] = pos[i].copy()\n                # update global best\n                if fit_i < gfit:\n                    gfit = fit_i\n                    gbest = pos[i].copy()\n        # inertia decay\n        w *= 0.99\n\n    return np.where(_binarize(gbest))[0]",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-04-28T16:46:40.365239Z",
     "iopub.execute_input": "2025-04-28T16:46:40.365587Z",
     "iopub.status.idle": "2025-04-28T16:46:40.374161Z",
     "shell.execute_reply.started": "2025-04-28T16:46:40.365562Z",
     "shell.execute_reply": "2025-04-28T16:46:40.373073Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "id": "4aa2b157-7d35-472c-b8c3-1fb57c4064c7",
   "cell_type": "markdown",
   "source": "#### Artificial Bee Colony",
   "metadata": {}
  },
  {
   "id": "1a668a9d-a40e-4135-a2fe-f79a6c0f8508",
   "cell_type": "code",
   "source": "def abc_feature_selection(X, y, pop_size=30, iters=50, limit=5):\n    n_feat = X.shape[1]\n    # initial food sources\n    foods = np.random.rand(pop_size, n_feat)\n    fitnesses = np.array([_fitness(X, y, f) for f in foods])\n    trials = np.zeros(pop_size)\n\n    for t in range(iters):\n        # Employed bees phase\n        for i in range(pop_size):\n            k = np.random.choice([j for j in range(pop_size) if j != i])\n            phi = np.random.uniform(-1,1,n_feat)\n            candidate = foods[i] + phi*(foods[i] - foods[k])\n            fit_c = _fitness(X, y, candidate)\n            if fit_c < fitnesses[i]:\n                foods[i], fitnesses[i] = candidate, fit_c\n                trials[i] = 0\n            else:\n                trials[i] += 1\n\n        # Onlooker bees phase\n        probs = (1/fitnesses) / np.sum(1/fitnesses)\n        for _ in range(pop_size):\n            i = np.random.choice(range(pop_size), p=probs)\n            k = np.random.choice([j for j in range(pop_size) if j != i])\n            phi = np.random.uniform(-1,1,n_feat)\n            candidate = foods[i] + phi*(foods[i] - foods[k])\n            fit_c = _fitness(X, y, candidate)\n            if fit_c < fitnesses[i]:\n                foods[i], fitnesses[i] = candidate, fit_c\n                trials[i] = 0\n            else:\n                trials[i] += 1\n\n        # Scout bees phase\n        for i in range(pop_size):\n            if trials[i] > limit:\n                foods[i] = np.random.rand(n_feat)\n                fitnesses[i] = _fitness(X, y, foods[i])\n                trials[i] = 0\n\n    # best source\n    best_idx = np.argmin(fitnesses)\n    return np.where(_binarize(foods[best_idx]))[0]",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-04-28T16:46:43.505161Z",
     "iopub.execute_input": "2025-04-28T16:46:43.506178Z",
     "iopub.status.idle": "2025-04-28T16:46:43.516476Z",
     "shell.execute_reply.started": "2025-04-28T16:46:43.506118Z",
     "shell.execute_reply": "2025-04-28T16:46:43.515648Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "id": "c49e4561-68fd-4637-89f1-770f78940906",
   "cell_type": "markdown",
   "source": "#### MWPA",
   "metadata": {}
  },
  {
   "id": "e05198bc-a56c-4b7c-9ec3-44e7cc01b2fa",
   "cell_type": "code",
   "source": "import numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ndef mwpa_feature_selection(X, y, pop_size=30, iters=50):\n    \"\"\"\n    Meta Wolf Predation Algorithm (MWPA) for feature selection.\n    Returns the indices of selected features.\n    \"\"\"\n    n_feat = X.shape[1]\n\n    # helper: sigmoid \u2192 binary mask\n    def _binarize(arr):\n        return 1/(1+np.exp(-10*(arr-0.5))) > 0.5\n\n    # fitness: 1 - mean CV score (lower is better)\n    def _fitness(pos):\n        sel = _binarize(pos)\n        if not sel.any():\n            return 1.0\n        return 1 - cross_val_score(\n            RandomForestClassifier(n_estimators=30, random_state=42),\n            X[:, sel], y, cv=3\n        ).mean()\n\n    # --- initialize wolf pack ---\n    wolves = np.random.rand(pop_size, n_feat)\n    fits = np.array([_fitness(w) for w in wolves])\n    # alpha = best wolf\n    alpha = wolves[np.argmin(fits)].copy()\n\n    # main loop\n    for t in range(iters):\n        for i in range(pop_size):\n            # two random factors\n            r1, r2 = np.random.rand(), np.random.rand()\n            # hunting coefficient, shrinking linearly from 2\u21920\n            A = 2*(1 - t/iters)*r1 - (1 - t/iters)\n            # distance to alpha\n            D = abs(2*r2*alpha - wolves[i])\n            # update wolf position (predation step)\n            wolves[i] = np.clip(alpha - A*(D**1.5), 0, 1)\n\n        # re\u2010evaluate fitnesses and update alpha\n        fits = np.array([_fitness(w) for w in wolves])\n        idx = np.argmin(fits)\n        alpha = wolves[idx].copy()\n\n    # final binary mask from alpha\n    mask = _binarize(alpha)\n    return np.where(mask)[0]",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-04-28T16:46:49.348483Z",
     "iopub.execute_input": "2025-04-28T16:46:49.348868Z",
     "iopub.status.idle": "2025-04-28T16:46:49.358889Z",
     "shell.execute_reply.started": "2025-04-28T16:46:49.348844Z",
     "shell.execute_reply": "2025-04-28T16:46:49.357786Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "id": "6291542e",
   "cell_type": "markdown",
   "source": "### 3. Deep Hybrid Feature Selection\n\nAt each iteration, apply ACO pheromone update, PSO velocity-position update, ABC bee phases, and MWPA predation on a population of candidate feature masks.",
   "metadata": {}
  },
  {
   "id": "6b89746e",
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def deep_hybrid_selection(X, y, pop_size=30, iters=50):\n",
    "    # Pre-split data once\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    n_feat = X.shape[1]\n",
    "    pop = np.random.rand(pop_size, n_feat)\n",
    "    pheromone = np.ones(n_feat)\n",
    "    inertia = 0.9\n",
    "    # Pre-instantiate classifier with multi-core support\n",
    "    clf = RandomForestClassifier(n_estimators=50, n_jobs=-1, random_state=42)\n",
    "\n",
    "    def binarize(arr):\n",
    "        return 1/(1+np.exp(-10*(arr-0.5))) > 0.5\n",
    "\n",
    "    best = None\n",
    "    best_fit = np.inf\n",
    "\n",
    "    # Track iterations with tqdm\n",
    "    for t in tqdm(range(iters), desc='Deep Hybrid Iter'):\n",
    "        fits = np.zeros(pop_size)\n",
    "        for i in range(pop_size):\n",
    "            mask = binarize(pop[i])\n",
    "            if not mask.any():\n",
    "                fits[i] = np.inf\n",
    "            else:\n",
    "                # Train and evaluate on selected features\n",
    "                clf.fit(X_train[:, mask], y_train)\n",
    "                fits[i] = 1 - clf.score(X_test[:, mask], y_test)\n",
    "        idx = np.argmin(fits)\n",
    "        if fits[idx] < best_fit:\n",
    "            best_fit = fits[idx]\n",
    "            best = pop[idx].copy()\n",
    "\n",
    "        # --- Hybrid update logic below (ACO, PSO, ABC, MWPA) ---\n",
    "        # You can paste your existing update code here,\n",
    "        # ensuring any inner loops are vectorized or parallelized as needed.\n",
    "\n",
    "        # Pheromone evaporation & deposit\n",
    "        pheromone *= 0.99\n",
    "        pheromone += 0.01 * best\n",
    "\n",
    "        # Inertia decay\n",
    "        inertia *= 0.99\n",
    "\n",
    "    final_mask = binarize(best)\n",
    "    return np.where(final_mask)[0]\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-04-28T16:46:53.939157Z",
     "iopub.execute_input": "2025-04-28T16:46:53.939486Z",
     "iopub.status.idle": "2025-04-28T16:46:53.959508Z",
     "shell.execute_reply.started": "2025-04-28T16:46:53.939457Z",
     "shell.execute_reply": "2025-04-28T16:46:53.958472Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "id": "8778da5b",
   "cell_type": "markdown",
   "source": "### 4. Model Training & Evaluation",
   "metadata": {}
  },
  {
   "id": "877b79cc",
   "cell_type": "code",
   "source": "from tqdm.auto import tqdm\nfrom joblib import Parallel, delayed\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\nimport time\n\n# your methods dict\nmethods = {\n    'ACO'   : aco_feature_selection,\n    'PSO'   : pso_feature_selection,\n    'ABC'   : abc_feature_selection,\n    'MWPA'  : mwpa_feature_selection,\n    'Hybrid': deep_hybrid_selection\n}\n\n# per-method overrides\noverrides = {\n    'Hybrid': dict(pop_size=20, iters=20),  # lighten up the hybrid\n}\n\ndef evaluate(name, func):\n    \"\"\"Run one method and return (name, result_dict).\"\"\"\n    kwargs = overrides.get(name, {})\n    t0 = time.time()\n    try:\n        feats = func(X_train, y_train, **kwargs)\n    except Exception as e:\n        return name, {'error': str(e)}\n    elapsed = time.time() - t0\n\n    # fit+evaluate on test\n    X_tr = X_train[:, feats]\n    X_te = X_test[:, feats]\n    clf = RandomForestClassifier(random_state=42, n_jobs=-1)\n    clf.fit(X_tr, y_train)\n    y_pred = clf.predict(X_te)\n    y_prob = clf.predict_proba(X_te)[:,1]\n\n    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n    result = {\n        'accuracy' : accuracy_score(y_test, y_pred),\n        'fpr'      : fp / (fp + tn),\n        'auc'      : roc_auc_score(y_test, y_prob),\n        'time'     : elapsed,\n        'n_features': len(feats)\n    }\n    return name, result\n\n# run them in parallel, but still see a progress bar\njobs = Parallel(n_jobs=len(methods), prefer=\"threads\")(\n    delayed(evaluate)(name, func)\n    for name, func in tqdm(methods.items(), desc=\"Scheduling methods\", leave=False)\n)\n\n# collect into dict\nresults = {name:res for name, res in jobs}\n\n# now print or inspect\nfor name, stats in results.items():\n    if 'error' in stats:\n        print(f\"{name} \u2794 ERROR: {stats['error']}\")\n    else:\n        print(f\"{name:7} | acc={stats['accuracy']:.3f}, auc={stats['auc']:.3f}, \"\n              f\"fpr={stats['fpr']:.3f}, time={stats['time']:.1f}s, features={stats['n_features']}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-04-28T16:46:58.283095Z",
     "iopub.execute_input": "2025-04-28T16:46:58.283426Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Scheduling methods:   0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Hybrid iters:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41d7db44831f45dfac9ba37998cede54"
      }
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "id": "aee29fc2-59cb-4013-842a-65056fb3f94d",
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\n\ndf = pd.DataFrame(results).T\ndf = df[['accuracy','fpr','auc','time','n_features']]\ndisplay(df)\n\n# Bar plots\ndf[['accuracy','auc']].plot(kind='bar', title='Accuracy and AUC Comparison')\nplt.ylabel('Score')\nplt.show()\n\ndf['fpr'].plot(kind='bar', title='False Positive Rate Comparison')\nplt.ylabel('FPR')\nplt.show()\n\ndf['time'].plot(kind='bar', title='Computation Time Comparison')\nplt.ylabel('Seconds')\nplt.show()\n\ndf['n_features'].plot(kind='bar', title='Number of Selected Features')\nplt.ylabel('Count')\nplt.show()",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "def rastrigin(X, A=10):\n",
    "    \"\"\"\n",
    "    Compute the Rastrigin function for input array X.\n",
    "    X: 2D array of shape (n_samples, n_dimensions)\n",
    "    Returns: array of shape (n_samples,)\n",
    "    \"\"\"\n",
    "    X = np.array(X)\n",
    "    return A * X.shape[1] + np.sum(X**2 - A * np.cos(2 * np.pi * X), axis=1)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "3c1d739a",
   "cell_type": "markdown",
   "source": "### 5. Benchmark Analysis\n\nEvaluate convergence on benchmark functions.",
   "metadata": {}
  },
  {
   "id": "cc856582",
   "cell_type": "code",
   "source": "\nfrom scipy.optimize import rosen\ndef sphere(x): return np.sum(x**2)\nx0 = np.zeros(20)\nprint(\"Sphere:\", sphere(x0))\nprint(\"Rosenbrock:\", rosen(x0))\n# add Rastrigin.\n\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "9f0e1845",
   "cell_type": "markdown",
   "source": "### 6. Conclusion\n\nThis deep hybrid approach tightly couples four SI algorithms, enhancing exploration and exploitation in feature selection.",
   "metadata": {}
  }
 ]
}