{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d147ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Python notebook:\n",
    "```python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7ca80d",
   "metadata": {},
   "source": [
    "# # 0. Setup & Imports\n",
    "#\n",
    "# Install dependencies and import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccd4511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries if not already installed\n",
    "# (Uncomment and run in environments like Google Colab)\n",
    "# !pip install pyswarms scikit-learn pandas numpy matplotlib seaborn scipy tqdm requests -q\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from io import StringIO\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, roc_curve, classification_report, f1_score, precision_score, recall_score\n",
    "from tqdm.notebook import tqdm # Use tqdm for progress bars\n",
    "import sys # Import sys to check Python version for get_feature_names_out\n",
    "import os # Import os to check file existence\n",
    "warnings.filterwarnings('ignore') # Suppress warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b936f",
   "metadata": {},
   "source": [
    "# # 1. Data Acquisition\n",
    "#\n",
    "# Load the NSL-KDD dataset from the specified GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b11a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs\n",
    "train_url    = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTrain%2B.txt\"\n",
    "test_url     = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTest%2B.txt\"\n",
    "features_url = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/Field%20Names.csv\"\n",
    "# Define column names based on the Field Names.csv structure\n",
    "# The CSV has 'feature_name,type'. We only need the names.\n",
    "# The last two columns in the data files are 'attack_type' and 'difficulty_level'.\n",
    "column_names = []\n",
    "try:\n",
    "print(\"Attempting to fetch feature names...\")\n",
    "features_response = requests.get(features_url)\n",
    "features_response.raise_for_status() # Check for request errors\n",
    "# Read the CSV, it has two columns, we need the first one\n",
    "features_df = pd.read_csv(StringIO(features_response.text), header=None)\n",
    "column_names = features_df[0].tolist()\n",
    "# Add the target and difficulty columns which are not in Field Names.csv\n",
    "column_names.extend(['attack_type', 'difficulty_level'])\n",
    "print(\"Feature names fetched successfully.\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching feature names: {e}\")\n",
    "# Fallback list if fetch fails\n",
    "column_names = [\n",
    "'duration','protocol_type','service','flag','src_bytes','dst_bytes','land',\n",
    "'wrong_fragment','urgent','hot','num_failed_logins','logged_in','num_compromised',\n",
    "'root_shell','su_attempted','num_root','num_file_creations','num_shells',\n",
    "'num_access_files','num_outbound_cmds','is_host_login','is_guest_login',\n",
    "'count','srv_count','serror_rate','srv_serror_rate','rerror_rate',\n",
    "'srv_rerror_rate','same_srv_rate','diff_srv_rate','srv_diff_host_rate',\n",
    "'dst_host_count','dst_host_srv_count','dst_host_same_srv_rate',\n",
    "'dst_host_diff_srv_rate','dst_host_same_src_port_rate',\n",
    "'dst_host_srv_diff_host_rate','dst_host_serror_rate',\n",
    "'dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate',\n",
    "'attack_type','difficulty_level']\n",
    "print(\"Using fallback feature names.\")\n",
    "# Fetch datasets\n",
    "df_train = None\n",
    "df_test = None\n",
    "data_loaded = False\n",
    "try:\n",
    "print(f\"\\nFetching training data from {train_url}...\")\n",
    "data_response = requests.get(train_url)\n",
    "data_response.raise_for_status() # Check for request errors\n",
    "df_train = pd.read_csv(StringIO(data_response.text), header=None, names=column_names)\n",
    "print(\"Training data loaded successfully.\")\n",
    "print(f\"Fetching testing data from {test_url}...\")\n",
    "test_response = requests.get(test_url)\n",
    "test_response.raise_for_status() # Check for request errors\n",
    "df_test = pd.read_csv(StringIO(test_response.text), header=None, names=column_names)\n",
    "print(\"Testing data loaded successfully.\")\n",
    "data_loaded = True\n",
    "print(\"\\nTraining data shape:\", df_train.shape)\n",
    "print(\"Testing data shape:\", df_test.shape)\n",
    "# Drop the 'difficulty_level' column as it's not a feature for detection\n",
    "if 'difficulty_level' in df_train.columns:\n",
    "df_train = df_train.drop('difficulty_level', axis=1)\n",
    "if 'difficulty_level' in df_test.columns:\n",
    "df_test = df_test.drop('difficulty_level', axis=1)\n",
    "# The 'attack_type' column contains specific attack names and 'normal'.\n",
    "# We need to convert this into a binary classification problem: 'normal' vs 'attack'.\n",
    "# Let's create a binary target variable: 1 for attack, 0 for normal.\n",
    "# Get unique attack types to understand the data\n",
    "print(\"\\nUnique attack types in training data:\")\n",
    "print(df_train['attack_type'].unique())\n",
    "# Create binary target variable\n",
    "df_train['is_attack'] = (df_train['attack_type'] != 'normal').astype(int)\n",
    "df_test['is_attack'] = (df_test['attack_type'] != 'normal').astype(int)\n",
    "# Drop the original 'attack_type' column\n",
    "df_train = df_train.drop('attack_type', axis=1)\n",
    "df_test = df_test.drop('attack_type', axis=1)\n",
    "print(\"\\nTraining data shape after dropping columns:\", df_train.shape)\n",
    "print(\"Testing data shape after dropping columns:\", df_test.shape)\n",
    "# Display the first few rows\n",
    "print(\"\\nTraining data head:\")\n",
    "print(df_train.head())\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data: {e}\")\n",
    "print(\"Please ensure you have an internet connection and the URLs are correct.\")\n",
    "print(\"Cannot proceed without data files.\")\n",
    "df_train = None\n",
    "df_test = None\n",
    "data_loaded = False\n",
    "except Exception as e:\n",
    "print(f\"An unexpected error occurred during data loading or initial processing: {e}\")\n",
    "df_train = None\n",
    "df_test = None\n",
    "data_loaded = False\n",
    "# Initialize empty data structures if data loading failed, to allow code structure to be viewed\n",
    "if not data_loaded:\n",
    "print(\"\\nData loading failed. Initializing empty data structures for notebook structure demonstration.\")\n",
    "# Use the column_names defined earlier, excluding the dropped ones\n",
    "feature_cols = [col for col in column_names if col not in ['attack_type', 'difficulty_level']]\n",
    "X_train_raw, y_train = pd.DataFrame(columns=feature_cols), pd.Series(dtype='int')\n",
    "X_test_raw, y_test = pd.DataFrame(columns=feature_cols), pd.Series(dtype='int')\n",
    "X_train_p, X_test_p = np.array([]).reshape(0, len(feature_cols)), np.array([]).reshape(0, len(feature_cols))\n",
    "X_tr, X_val, y_tr, y_val = np.array([]).reshape(0, len(feature_cols)), np.array([]).reshape(0, len(feature_cols)), pd.Series(dtype='int'), pd.Series(dtype='int')\n",
    "feat_names = feature_cols # Use original names as fallback\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf550bee",
   "metadata": {},
   "source": [
    "# # 2. Data Preprocessing\n",
    "#\n",
    "# This step involves:\n",
    "# - Handling missing values (NSL-KDD is relatively clean, but good practice to check).\n",
    "# - Encoding categorical features (`protocol_type`, `service`, `flag`) using **One-Hot Encoding**.\n",
    "# - Scaling numerical features using **MinMaxScaler**.\n",
    "# - Splitting the training data into training (`X_tr`, `y_tr`) and validation (`X_val`, `y_val`) sets for use in the feature selection fitness function. The original test set (`X_test_p`, `y_test`) is kept separate for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a252cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_loaded:\n",
    "# Split features/target\n",
    "X_train_raw, y_train = df_train.drop('is_attack', axis=1), df_train['is_attack']\n",
    "X_test_raw,  y_test  = df_test.drop('is_attack', axis=1),  df_test['is_attack']\n",
    "# Identify categorical vs numeric\n",
    "# Ensure we only select columns that exist in the dataframe\n",
    "all_features = X_train_raw.columns.tolist()\n",
    "cat_feats = [col for col in ['protocol_type', 'service', 'flag'] if col in all_features]\n",
    "num_feats = [col for col in all_features if col not in cat_feats]\n",
    "print(f\"\\nCategorical features: {cat_feats}\")\n",
    "print(f\"Numerical features: {num_feats}\")\n",
    "# Pipelines\n",
    "num_pipe = Pipeline([\n",
    "('impute', SimpleImputer(strategy='median')),\n",
    "('scale', MinMaxScaler())\n",
    "])\n",
    "cat_pipe = Pipeline([\n",
    "('impute', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "# Create a column transformer to apply different transformations to different columns\n",
    "# Use remainder='passthrough' to keep any columns not explicitly listed (shouldn't be any here)\n",
    "pre = ColumnTransformer([\n",
    "('num', num_pipe, num_feats),\n",
    "('cat', cat_pipe, cat_feats)\n",
    "], remainder='passthrough')\n",
    "# Fit/transform\n",
    "# Fit the preprocessor only on the training data to avoid data leakage\n",
    "X_train_p = pre.fit_transform(X_train_raw)\n",
    "X_test_p  = pre.transform(X_test_raw)\n",
    "# Feature names after preprocessing\n",
    "try:\n",
    "# For sklearn >= 1.0\n",
    "feat_names = pre.get_feature_names_out()\n",
    "except AttributeError:\n",
    "# For older sklearn versions, this is more manual\n",
    "cat_names = pre.named_transformers_['cat']['onehot'].get_feature_names(cat_feats)\n",
    "feat_names = num_feats + list(cat_names)\n",
    "# Handle remainder='passthrough' if used\n",
    "if pre.remainder == 'passthrough':\n",
    "passthrough_cols = [col for col in X_train_raw.columns if col not in num_feats and col not in cat_feats]\n",
    "feat_names.extend(passthrough_cols)\n",
    "# Create internal train/val split for FS fitness\n",
    "# Use the processed training data for splitting\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "X_train_p, y_train, test_size=0.25, stratify=y_train, random_state=42\n",
    ")\n",
    "print(\"Processed shapes: X_train_processed:\", X_train_p.shape, \"X_test_processed:\", X_test_p.shape)\n",
    "print(\"Feature selection splits: X_tr:\", X_tr.shape, \"X_val:\", X_val.shape)\n",
    "print(f\"Number of features after preprocessing: {len(feat_names)}\")\n",
    "else:\n",
    "print(\"\\nSkipping preprocessing as data was not loaded.\")\n",
    "# Ensure these variables exist even if data loading failed\n",
    "X_train_raw, y_train = pd.DataFrame(), pd.Series(dtype='int')\n",
    "X_test_raw, y_test = pd.DataFrame(), pd.Series(dtype='int')\n",
    "X_train_p, X_test_p = np.array([]).reshape(0,0), np.array([]).reshape(0,0)\n",
    "X_tr, X_val, y_tr, y_val = np.array([]).reshape(0,0), np.array([]).reshape(0,0), pd.Series(dtype='int'), pd.Series(dtype='int')\n",
    "feat_names = []\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a51390",
   "metadata": {},
   "source": [
    "# # 3. Define Fitness Function\n",
    "#\n",
    "# Define a single fitness function that will be used by all swarm intelligence algorithms (individual and hybrid) for feature selection.\n",
    "#\n",
    "# - It takes a binary feature mask as input.\n",
    "# - It trains a **fast classifier** (Logistic Regression) on the training split (`X_tr`, `y_tr`) using only the features indicated by the mask.\n",
    "# - It evaluates the classifier's **accuracy** on the validation split (`X_val`, `y_val`).\n",
    "# - It calculates fitness as `Accuracy - alpha * (Number of Selected Features / Total Features)`. This function **maximizes** fitness.\n",
    "# - It handles edge cases like no features being selected or errors during training/evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71709c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_loaded and X_tr.shape[0] > 0:\n",
    "# Define the fitness function for feature selection\n",
    "def feature_fitness(mask, X_train_subset, y_train_subset, X_val_subset, y_val_subset, alpha=0.05):\n",
    "\"\"\"\n",
    "Evaluates the fitness of a feature subset using a simple classifier on a validation set.\n",
    "Fitness = Accuracy - alpha * (Number of Selected Features / Total Features)\n",
    "Maximizing this fitness means maximizing accuracy and minimizing features.\n",
    "\"\"\"\n",
    "selected_indices = np.where(mask == 1)[0]\n",
    "total_features = len(mask)\n",
    "# If no features are selected, return a very low fitness\n",
    "if len(selected_indices) == 0:\n",
    "return -1.0\n",
    "# Select features from the data subsets\n",
    "X_train_selected = X_train_subset[:, selected_indices]\n",
    "X_val_selected = X_val_subset[:, selected_indices]\n",
    "# Train a simple classifier (e.g., Logistic Regression)\n",
    "# Use a small max_iter for speed during feature selection\n",
    "# Handle potential errors during training (e.g., if selected features are all zero variance)\n",
    "try:\n",
    "# Check for sufficient samples and features\n",
    "if X_train_selected.shape[0] < 2 or X_train_selected.shape[1] == 0:\n",
    "return -1.0 # Not enough data or features\n",
    "# Use a fast classifier like Logistic Regression\n",
    "# Add a small regularization (C) and handle potential convergence warnings\n",
    "clf = LogisticRegression(max_iter=200, solver='liblinear', random_state=42, C=0.1)\n",
    "clf.fit(X_train_selected, y_train_subset)\n",
    "# Evaluate on the validation set\n",
    "accuracy = clf.score(X_val_selected, y_val_subset) # Use score for accuracy\n",
    "# Penalty for number of features\n",
    "num_selected = len(selected_indices)\n",
    "feature_penalty = alpha * (num_selected / total_features)\n",
    "fitness = accuracy - feature_penalty\n",
    "# Return a very low fitness if accuracy is NaN or problematic\n",
    "if np.isnan(fitness):\n",
    "return -1.0\n",
    "return fitness\n",
    "except Exception as e:\n",
    "# print(f\"Error during fitness evaluation: {e}\") # Uncomment for debugging\n",
    "return -1.0 # Return low fitness on error\n",
    "print(\"\\nFeature selection fitness function defined.\")\n",
    "else:\n",
    "print(\"\\nSkipping fitness function definition as data was not loaded or split.\")\n",
    "# Define a dummy function to avoid errors if called\n",
    "def feature_fitness(mask, X_train_subset, y_train_subset, X_val_subset, y_val_subset, alpha=0.05):\n",
    "print(\"Fitness function called but data not loaded.\")\n",
    "return -1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f247c9",
   "metadata": {},
   "source": [
    "# # 4. Implement Individual Swarm FS Algorithms\n",
    "#\n",
    "# Implement the individual ACO, PSO, ABC, and MWPA algorithms for binary feature selection. These will serve as benchmarks to compare against the hybrid approach.\n",
    "#\n",
    "# - Each function will take the data splits (`X_tr`, `y_tr`, `X_val`, `y_val`) and algorithm parameters.\n",
    "# - They will use the `feature_fitness` function defined in Step 3.\n",
    "# - They will return the best selected feature mask (binary vector), the fitness history, and computational time.\n",
    "#\n",
    "# **Note:** The implementations below are adapted from your provided snippets and use the corrected fitness function. MWPA implementation is based on the structure provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21de1f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "if data_loaded and X_tr.shape > 0:\n",
    "n_features_fs = X_tr.shape\n",
    "# Helper function to convert continuous position to binary mask\n",
    "# Used by PSO, ABC, MWPA\n",
    "def _binarize(pos, threshold=0.5):\n",
    "\"\"\"Sigmoid thresholding for continuous positions.\"\"\"\n",
    "# Apply sigmoid to map values to (0, 1)\n",
    "# Use a steeper sigmoid (e.g., 10x or 20x) for clearer binarization\n",
    "sigmoid_output = 1 / (1 + np.exp(-15 * (pos - threshold)))\n",
    "# Threshold to get binary mask\n",
    "return (sigmoid_output > threshold).astype(int)\n",
    "# --- Ant Colony Optimization (ACO) for Feature Selection ---\n",
    "def aco_fs(X_train_subset, y_train_subset, X_val_subset, y_val_subset,\n",
    "n_agents=30, max_iter=50, evap_rate=0.1, alpha_fitness=0.05):\n",
    "\"\"\"\n",
    "Ant Colony Optimization for binary feature selection.\n",
    "Uses the feature_fitness function.\n",
    "\"\"\"\n",
    "n_feat = X_train_subset.shape\n",
    "# Pheromone trail on each feature (higher pheromone -> more likely to be selected)\n",
    "pher = np.ones(n_feat) * 0.1 # Initialize pheromones\n",
    "best_mask = np.zeros(n_feat, dtype=int)\n",
    "best_fit = -np.inf\n",
    "fitness_history = []\n",
    "# print(\"\\nRunning ACO Feature Selection...\") # Moved print outside\n",
    "start_time = time.time()\n",
    "for t in range(max_iter):\n",
    "ants_masks = []\n",
    "fits = []\n",
    "# Calculate selection probability for each feature\n",
    "# Probability of selecting feature i = pheromone[i] / sum(pheromones)\n",
    "# Add a small epsilon to avoid division by zero if all pheromones are zero\n",
    "prob = (pher + 1e-9) / (np.sum(pher) + 1e-9)\n",
    "for i in range(n_agents):\n",
    "# Build ant solution: probabilistically decide whether to include each feature\n",
    "mask = (np.random.rand(n_feat) < prob).astype(int)\n",
    "ants_masks.append(mask)\n",
    "# Evaluate fitness using the common fitness function\n",
    "fit_i = feature_fitness(mask, X_train_subset, y_train_subset, X_val_subset, y_val_subset, alpha=alpha_fitness)\n",
    "fits.append(fit_i)\n",
    "# Update global best based on MAXIMUM fitness\n",
    "current_fits = np.array(fits)\n",
    "# Handle case where all fits are -inf\n",
    "if np.max(current_fits) > best_fit:\n",
    "best_current_idx = np.argmax(current_fits)\n",
    "current_best_fit = current_fits[best_current_idx]\n",
    "current_best_mask = ants_masks[best_current_idx]\n",
    "if current_best_fit > best_fit:\n",
    "best_fit = current_best_fit\n",
    "best_mask = current_best_mask.copy()\n",
    "# Pheromone evaporation\n",
    "pher *= (1 - evap_rate)\n",
    "# Pheromone deposit: Deposit pheromone on features in the best mask found so far (Elitist ACO)\n",
    "# Deposit amount could be proportional to fitness or a fixed value\n",
    "if best_fit > -np.inf: # Only deposit if a valid solution was found\n",
    "deposit = best_fit # Example: Deposit amount is the best fitness\n",
    "pher[best_mask == 1] += deposit\n",
    "# Ensure pheromones don't become negative or too small (optional clipping)\n",
    "pher = np.maximum(pher, 1e-2) # Keep pheromones slightly positive\n",
    "fitness_history.append(best_fit)\n",
    "# print(f\"  ACO Iter {t+1}/{max_iter}, Best Fit: {best_fit:.4f}, Selected: {np.sum(best_mask)}\") # Uncomment for verbose\n",
    "end_time = time.time()\n",
    "comp_time = end_time - start_time\n",
    "# print(f\"ACO finished in {comp_time:.2f} seconds. Best Fitness: {best_fit:.4f}, Selected Features: {np.sum(best_mask)}\") # Moved print outside\n",
    "return best_mask, fitness_history, comp_time\n",
    "# --- Particle Swarm Optimization (PSO) for Feature Selection ---\n",
    "# This is a binary PSO adaptation using continuous positions and binarization\n",
    "def pso_fs(X_train_subset, y_train_subset, X_val_subset, y_val_subset,\n",
    "n_agents=30, max_iter=50, w=0.7, c1=1.5, c2=1.5, alpha_fitness=0.05):\n",
    "\"\"\"\n",
    "Binary Particle Swarm Optimization for feature selection.\n",
    "Uses the feature_fitness function.\n",
    "\"\"\"\n",
    "n_feat = X_train_subset.shape\n",
    "# Positions are continuous, velocities are continuous\n",
    "pos = np.random.rand(n_agents, n_feat)\n",
    "vel = np.zeros_like(pos) # Initialize velocities to zero\n",
    "# Personal bests (positions and fitnesses)\n",
    "pbest_pos = pos.copy()\n",
    "pbest_fit = np.full(n_agents, -np.inf)\n",
    "# Global best (position and fitness)\n",
    "gbest_pos = np.zeros(n_feat) # Initialize global best position\n",
    "gbest_fit = -np.inf\n",
    "fitness_history = []\n",
    "# print(\"\\nRunning PSO Feature Selection...\") # Moved print outside\n",
    "start_time = time.time()\n",
    "# Evaluate initial population to set initial personal and global bests\n",
    "for i in range(n_agents):\n",
    "fit_i = feature_fitness(_binarize(pos[i]), X_train_subset, y_train_subset, X_val_subset, y_val_subset, alpha=alpha_fitness)\n",
    "pbest_fit[i] = fit_i\n",
    "pbest_pos[i] = pos[i].copy()\n",
    "if fit_i > gbest_fit:\n",
    "gbest_fit = fit_i\n",
    "gbest_pos = pos[i].copy()\n",
    "fitness_history.append(gbest_fit)\n",
    "for t in range(max_iter):\n",
    "# Update inertia weight (linear decay example)\n",
    "current_w = w * (max_iter - t) / max_iter # Linear decay from w to 0\n",
    "for i in range(n_agents):\n",
    "r1, r2 = np.random.rand(n_feat), np.random.rand(n_feat)\n",
    "# Update velocity (standard PSO velocity update)\n",
    "vel[i] = current_w * vel[i] + c1 * r1 * (pbest_pos[i] - pos[i]) + c2 * r2 * (gbest_pos - pos[i])\n",
    "# Update position (standard PSO position update for continuous space)\n",
    "pos[i] += vel[i]\n",
    "# Apply bounds to position\n",
    "pos[i] = np.clip(pos[i], 0, 1)\n",
    "# Evaluate fitness of the BINARY mask derived from the continuous position\n",
    "current_mask = _binarize(pos[i])\n",
    "fit_i = feature_fitness(current_mask, X_train_subset, y_train_subset, X_val_subset, y_val_subset, alpha=alpha_fitness)\n",
    "# Update personal best (based on MAXIMUM fitness)\n",
    "if fit_i > pbest_fit[i]:\n",
    "pbest_fit[i] = fit_i\n",
    "pbest_pos[i] = pos[i].copy()\n",
    "# Update global best (based on MAXIMUM fitness)\n",
    "if fit_i > gbest_fit:\n",
    "gbest_fit = fit_i\n",
    "gbest_pos = pos[i].copy()\n",
    "fitness_history.append(gbest_fit)\n",
    "# print(f\"  PSO Iter {t+1}/{max_iter}, Best Fit: {gbest_fit:.4f}, Selected: {np.sum(_binarize(gbest_pos))}\") # Uncomment for verbose\n",
    "end_time = time.time()\n",
    "comp_time = end_time - start_time\n",
    "final_mask = _binarize(gbest_pos) # Final mask is from the global best position\n",
    "# print(f\"PSO finished in {comp_time:.2f} seconds. Best Fitness: {gbest_fit:.4f}, Selected Features: {np.sum(final_mask)}\") # Moved print outside\n",
    "return final_mask, fitness_history, comp_time\n",
    "# --- Artificial Bee Colony (ABC) for Feature Selection ---\n",
    "# This is a continuous ABC adaptation for positions\n",
    "def abc_fs(X_train_subset, y_train_subset, X_val_subset, y_val_subset,\n",
    "n_agents=30, max_iter=50, limit=5, alpha_fitness=0.05):\n",
    "\"\"\"\n",
    "Artificial Bee Colony for binary feature selection.\n",
    "Uses the feature_fitness function.\n",
    "\"\"\"\n",
    "n_feat = X_train_subset.shape\n",
    "n_employed = n_agents // 2 # Half are employed, half are onlooker\n",
    "n_onlooker = n_agents - n_employed\n",
    "# Food sources (positions) are continuous\n",
    "foods = np.random.rand(n_employed, n_feat)\n",
    "fitnesses = np.full(n_employed, -np.inf)\n",
    "trials = np.zeros(n_employed, dtype=int) # Trial counts for scout phase\n",
    "best_mask = np.zeros(n_feat, dtype=int)\n",
    "best_fit = -np.inf\n",
    "fitness_history = []\n",
    "# print(\"\\nRunning ABC Feature Selection...\") # Moved print outside\n",
    "start_time = time.time()\n",
    "# Evaluate initial food sources\n",
    "for i in range(n_employed):\n",
    "fitnesses[i] = feature_fitness(_binarize(foods[i]), X_train_subset, y_train_subset, X_val_subset, y_val_subset, alpha=alpha_fitness)\n",
    "if fitnesses[i] > best_fit:\n",
    "best_fit = fitnesses[i]\n",
    "best_mask = _binarize(foods[i]).copy()\n",
    "fitness_history.append(best_fit)\n",
    "for t in range(max_iter):\n",
    "# --- Employed bees phase ---\n",
    "for i in range(n_employed):\n",
    "# Select a random neighbor food source (j != i)\n",
    "# Ensure there's at least one other food source\n",
    "if n_employed > 1:\n",
    "neighbor_idx = np.random.choice([j for j in range(n_employed) if j != i])\n",
    "else:\n",
    "neighbor_idx = i # If only one, compare to itself (no change)\n",
    "# Generate a new candidate solution\n",
    "phi = np.random.uniform(-1, 1, n_feat)\n",
    "candidate_pos = foods[i] + phi * (foods[i] - foods[neighbor_idx])\n",
    "# Apply bounds\n",
    "candidate_pos = np.clip(candidate_pos, 0, 1)\n",
    "# Evaluate candidate fitness\n",
    "candidate_mask = _binarize(candidate_pos)\n",
    "candidate_fit = feature_fitness(candidate_mask, X_train_subset, y_train_subset, X_val_subset, y_val_subset, alpha=alpha_fitness)\n",
    "# Greedy selection: Replace food source if candidate is better (MAXIMIZING fitness)\n",
    "if candidate_fit > fitnesses[i]:\n",
    "foods[i] = candidate_pos\n",
    "fitnesses[i] = candidate_fit\n",
    "trials[i] = 0 # Reset trial count\n",
    "else:\n",
    "trials[i] += 1 # Increment trial count\n",
    "# Update global best after employed phase\n",
    "current_best_employed_idx = np.argmax(fitnesses)\n",
    "if fitnesses[current_best_employed_idx] > best_fit:\n",
    "best_fit = fitnesses[current_best_employed_idx]\n",
    "best_mask = _binarize(foods[current_best_employed_idx]).copy()\n",
    "# --- Onlooker bees phase ---\n",
    "# Calculate selection probabilities based on fitness (higher fitness -> higher probability)\n",
    "# Avoid division by zero or negative fitness if using 1/fitness\n",
    "# Using softmax-like probability based on positive fitness values\n",
    "# Add a small constant to fitness to make all values positive for probability calculation\n",
    "positive_fitnesses = fitnesses - np.min(fitnesses) + 1e-9 # Shift to positive, add epsilon\n",
    "total_fitness = np.sum(positive_fitnesses)\n",
    "selection_probs = positive_fitnesses / total_fitness if total_fitness > 0 else np.ones(n_employed) / n_employed\n",
    "# Onlookers select food sources based on probabilities and search around them\n",
    "if total_fitness > 0 and n_employed > 1: # Only proceed if there's at least one non-negative fitness and enough sources\n",
    "selected_indices = np.random.choice(n_employed, size=n_onlooker, p=selection_probs)\n",
    "for i in range(n_onlooker):\n",
    "selected_food_idx = selected_indices[i]\n",
    "# Select a random neighbor food source (j != selected_food_idx)\n",
    "neighbor_idx = np.random.choice([j for j in range(n_employed) if j != selected_food_idx])\n",
    "# Generate a new candidate solution\n",
    "phi = np.random.uniform(-1, 1, n_feat)\n",
    "candidate_pos = foods[selected_food_idx] + phi * (foods[selected_food_idx] - foods[neighbor_idx])\n",
    "# Apply bounds\n",
    "candidate_pos = np.clip(candidate_pos, 0, 1)\n",
    "# Evaluate candidate fitness\n",
    "candidate_mask = _binarize(candidate_pos)\n",
    "candidate_fit = feature_fitness(candidate_mask, X_train_subset, y_train_subset, X_val_subset, y_val_subset, alpha=alpha_fitness)\n",
    "# Greedy selection: Replace food source if candidate is better (MAXIMIZING fitness)\n",
    "if candidate_fit > fitnesses[selected_food_idx]:\n",
    "foods[selected_food_idx] = candidate_pos\n",
    "fitnesses[selected_food_idx] = candidate_fit\n",
    "trials[selected_food_idx] = 0 # Reset trial count\n",
    "else:\n",
    "trials[selected_food_idx] += 1 # Increment trial count\n",
    "# Update global best after onlooker phase\n",
    "current_best_onlooker_idx = np.argmax(fitnesses)\n",
    "if fitnesses[current_best_onlooker_idx] > best_fit:\n",
    "best_fit = fitnesses[current_best_onlooker_idx]\n",
    "best_mask = _binarize(foods[current_best_onlooker_idx]).copy()\n",
    "# --- Scout bees phase ---\n",
    "# Identify exhausted food sources (trials > limit)\n",
    "scout_indices = np.where(trials >= limit) # Get indices as a numpy array\n",
    "for i in scout_indices:\n",
    "# Replace exhausted food source with a new randomly generated one\n",
    "foods[i] = np.random.rand(n_feat)\n",
    "fitnesses[i] = feature_fitness(_binarize(foods[i]), X_train_subset, y_train_subset, X_val_subset, y_val_subset, alpha=alpha_fitness)\n",
    "trials[i] = 0 # Reset trial count\n",
    "# Update global best if the new scout solution is better\n",
    "if fitnesses[i] > best_fit:\n",
    "best_fit = fitnesses[i]\n",
    "best_mask = _binarize(foods[i]).copy()\n",
    "fitness_history.append(best_fit)\n",
    "# print(f\"  ABC Iter {t+1}/{max_iter}, Best Fit: {best_fit:.4f}, Selected: {np.sum(best_mask)}\") # Uncomment for verbose\n",
    "end_time = time.time()\n",
    "comp_time = end_time - start_time\n",
    "final_mask = _binarize(foods[np.argmax(fitnesses)]) # Final mask is from the best food source at the end\n",
    "# print(f\"ABC finished in {comp_time:.2f} seconds. Best Fitness: {best_fit:.4f}, Selected Features: {np.sum(final_mask)}\") # Moved print outside\n",
    "return final_mask, fitness_history, comp_time\n",
    "# --- Modified Wolf Predation Algorithm (MWPA) for Feature Selection ---\n",
    "# This is a continuous MWPA adaptation for positions\n",
    "# Based on the structure provided in the PDF snippet.\n",
    "def mwpa_fs(X_train_subset, y_train_subset, X_val_subset, y_val_subset,\n",
    "n_agents=30, max_iter=50, alpha_fitness=0.05):\n",
    "\"\"\"\n",
    "Modified Wolf Predation Algorithm (MWPA) for binary feature selection.\n",
    "Uses the feature_fitness function.\n",
    "\"\"\"\n",
    "n_feat = X_train_subset.shape\n",
    "# Initialize wolf pack (positions are continuous)\n",
    "wolves = np.random.rand(n_agents, n_feat)\n",
    "fits = np.full(n_agents, -np.inf)\n",
    "# Alpha wolf (best wolf)\n",
    "alpha_pos = np.zeros(n_feat) # Initialize alpha position\n",
    "alpha_fit = -np.inf\n",
    "best_mask = np.zeros(n_feat, dtype=int)\n",
    "best_fit = -np.inf\n",
    "fitness_history = []\n",
    "# print(\"\\nRunning MWPA Feature Selection...\") # Moved print outside\n",
    "start_time = time.time()\n",
    "# Evaluate initial wolf pack to find initial alpha\n",
    "for i in range(n_agents):\n",
    "fits[i] = feature_fitness(_binarize(wolves[i]), X_train_subset, y_train_subset, X_val_subset, y_val_subset, alpha=alpha_fitness)\n",
    "if fits[i] > alpha_fit:\n",
    "alpha_fit = fits[i]\n",
    "alpha_pos = wolves[i].copy()\n",
    "best_fit = alpha_fit # Initial best is alpha's fitness\n",
    "best_mask = _binarize(alpha_pos).copy()\n",
    "fitness_history.append(best_fit)\n",
    "for t in range(max_iter):\n",
    "# Update alpha wolf based on current best fitness in the pack\n",
    "current_best_idx = np.argmax(fits)\n",
    "if fits[current_best_idx] > alpha_fit:\n",
    "alpha_fit = fits[current_best_idx]\n",
    "alpha_pos = wolves[current_best_idx].copy()\n",
    "# Update global best if alpha is better than overall best found so far\n",
    "if alpha_fit > best_fit:\n",
    "best_fit = alpha_fit\n",
    "best_mask = _binarize(alpha_pos).copy()\n",
    "# Main loop for wolf predation behavior\n",
    "for i in range(n_agents):\n",
    "# Two random factors\n",
    "r1, r2 = np.random.rand(), np.random.rand()\n",
    "# Hunting coefficient, shrinking linearly from 2 to 0\n",
    "A = 2 * (1 - t / max_iter) * r1\n",
    "# Distance to alpha (prey)\n",
    "D = np.abs(2 * r2 * alpha_pos - wolves[i])\n",
    "# Update wolf position (predation step)\n",
    "# The update rule from the PDF snippet: alpha - A * (D**1.5)\n",
    "# This is a position update.\n",
    "wolves[i] = np.clip(alpha_pos - A * (D**1.5), 0, 1)\n",
    "# Re-evaluate fitnesses and update alpha for the next iteration\n",
    "for i in range(n_agents):\n",
    "fits[i] = feature_fitness(_binarize(wolves[i]), X_train_subset, y_train_subset, X_val_subset, y_val_subset, alpha=alpha_fitness)\n",
    "fitness_history.append(best_fit)\n",
    "# print(f\"  MWPA Iter {t+1}/{max_iter}, Best Fit: {best_fit:.4f}, Selected: {np.sum(best_mask)}\") # Uncomment for verbose\n",
    "end_time = time.time()\n",
    "comp_time = end_time - start_time\n",
    "final_mask = _binarize(alpha_pos) # Final mask is from the best wolf position\n",
    "# print(f\"MWPA finished in {comp_time:.2f} seconds. Best Fitness: {best_fit:.4f}, Selected Features: {np.sum(final_mask)}\") # Moved print outside\n",
    "return final_mask, fitness_history, comp_time\n",
    "else:\n",
    "print(\"\\nSkipping individual swarm algorithm definitions as data was not loaded or split.\")\n",
    "# Define dummy functions to avoid errors if called\n",
    "def aco_fs(*args, **kwargs): return np.array([]), [], 0\n",
    "def pso_fs(*args, **kwargs): return np.array([]), [], 0\n",
    "def abc_fs(*args, **kwargs): return np.array([]), [], 0\n",
    "def mwpa_fs(*args, **kwargs): return np.array([]), [], 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000fcb00",
   "metadata": {},
   "source": [
    "# # 5. Implement Plausible Hybrid Swarm Intelligence for Feature Selection\n",
    "#\n",
    "# Implement a plausible hybrid ACO+PSO+ABC+MWPA algorithm for binary feature selection. This implementation attempts to combine the search mechanisms within a single iterative loop.\n",
    "#\n",
    "# - This class `HybridSwarmFeatureSelector` manages the population and the iteration process.\n",
    "# - It uses the `feature_fitness` function.\n",
    "# - The `update_agents` method implements the hybridization logic. A common strategy is to apply different update rules (or combinations) probabilistically to agents in each iteration. This implementation uses a probabilistic approach where each agent applies one of the component-inspired updates (ACO, PSO+MWPA, ABC).\n",
    "# - It returns the best selected feature mask, fitness history, and computational time.\n",
    "#\n",
    "# **Note:** This is a *plausible interpretation* of how these algorithms could be hybridized for binary feature selection. Your specific novel algorithm might differ. You should replace the logic inside `initialize_agents` and `update_agents` with your precise implementation if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "if data_loaded and X_tr.shape[0] > 0:\n",
    "n_features_hybrid = X_tr.shape[1]\n",
    "# --- Plausible Hybrid Swarm Intelligence Algorithm for Feature Selection ---\n",
    "class HybridSwarmFeatureSelector:\n",
    "def __init__(self, n_features, n_agents=50, max_iter=50, alpha_fitness=0.05,\n",
    "pso_w=0.7, pso_c1=1.5, pso_c2=1.5, aco_evap=0.1, aco_deposit=0.1,\n",
    "abc_limit=5, mwpa_beta=1.5, hybrid_probs=[0.33, 0.33, 0.34]): # Probabilities for [ACO, PSO+MWPA, ABC]\n",
    "\"\"\"\n",
    "Initializes the hybrid swarm intelligence feature selector.\n",
    "Uses a probabilistic approach to apply component-inspired updates.\n",
    "\"\"\"\n",
    "self.n_features = n_features\n",
    "self.n_agents = n_agents\n",
    "self.max_iter = max_iter\n",
    "self.alpha_fitness = alpha_fitness # Weight for feature penalty in fitness function\n",
    "# Algorithm parameters\n",
    "self.pso_w = pso_w\n",
    "self.pso_c1 = pso_c1\n",
    "self.pso_c2 = pso_c2\n",
    "self.aco_evap = aco_evap\n",
    "self.aco_deposit = aco_deposit\n",
    "self.abc_limit = abc_limit\n",
    "self.mwpa_beta = mwpa_beta\n",
    "self.hybrid_probs = hybrid_probs # Probabilities for selecting update type\n",
    "# Agent state (continuous positions for PSO/ABC/MWPA base)\n",
    "self.agents_pos = np.random.rand(self.n_agents, self.n_features)\n",
    "self.velocities = np.zeros_like(self.agents_pos) # For PSO part\n",
    "self.pbest_pos = self.agents_pos.copy()\n",
    "self.pbest_fit = np.full(self.n_agents, -np.inf)\n",
    "# Global best (shared)\n",
    "self.gbest_pos = np.zeros(self.n_features)\n",
    "self.gbest_fit = -np.inf\n",
    "self.best_feature_mask = np.zeros(self.n_features, dtype=int) # Overall best mask\n",
    "# ACO components (pheromone trail on each feature)\n",
    "self.pheromones = np.ones(self.n_features) * 0.1\n",
    "# ABC components (trial counts for scout phase)\n",
    "self.trials = np.zeros(self.n_agents, dtype=int)\n",
    "# MWPA components (alpha wolf is the global best)\n",
    "# Hunting coefficient A will be calculated per iteration/agent\n",
    "self.fitness_history = [] # To track convergence\n",
    "self.computational_time = 0 # To track time\n",
    "# Store data splits for fitness evaluation\n",
    "self.X_train_val = None\n",
    "self.y_train_val = None\n",
    "self.X_val = None\n",
    "self.y_val = None\n",
    "print(\"HybridSwarmFeatureSelector initialized.\")\n",
    "def initialize_agents(self):\n",
    "\"\"\"\n",
    "Initialize the population of agents (continuous positions) and algorithm-specific components.\n",
    "\"\"\"\n",
    "# Initialize agents as random continuous vectors in [0, 1]\n",
    "self.agents_pos = np.random.rand(self.n_agents, self.n_features)\n",
    "self.velocities = np.zeros_like(self.agents_pos) # For PSO part\n",
    "self.pbest_pos = self.agents_pos.copy()\n",
    "self.pbest_fit = np.full(self.n_agents, -np.inf)\n",
    "# Initialize pheromones\n",
    "self.pheromones = np.ones(self.n_features) * 0.1\n",
    "# Initialize trial counts for ABC\n",
    "self.trials = np.zeros(self.n_agents, dtype=int)\n",
    "# Evaluate initial population to set initial personal and global bests\n",
    "initial_fitnesses = [feature_fitness(_binarize(pos), self.X_train_val, self.y_train_val, self.X_val, self.y_val, self.alpha_fitness) for pos in self.agents_pos]\n",
    "# Find initial best (MAXIMIZING fitness)\n",
    "if max(initial_fitnesses) > -np.inf:\n",
    "best_initial_idx = np.argmax(initial_fitnesses)\n",
    "self.gbest_fit = initial_fitnesses[best_initial_idx]\n",
    "self.gbest_pos = self.agents_pos[best_initial_idx].copy()\n",
    "self.best_fitness = self.gbest_fit\n",
    "self.best_feature_mask = _binarize(self.gbest_pos).copy()\n",
    "else:\n",
    "# If all initial solutions are invalid\n",
    "self.gbest_fit = -np.inf\n",
    "self.gbest_pos = np.random.rand(self.n_features) # Still need a starting point for gbest_pos update\n",
    "self.best_fitness = -np.inf\n",
    "self.best_feature_mask = np.zeros(self.n_features, dtype=int)\n",
    "self.pbest_fit = np.array(initial_fitnesses)\n",
    "def update_agents(self, iteration):\n",
    "\"\"\"\n",
    "Perform one iteration of the hybrid swarm intelligence algorithm for feature selection.\n",
    "Applies component-inspired updates probabilistically to each agent.\n",
    "\"\"\"\n",
    "new_agents_pos = self.agents_pos.copy()\n",
    "new_velocities = self.velocities.copy()\n",
    "current_fitnesses = np.full(self.n_agents, -np.inf) # To store fitnesses of updated agents\n",
    "# Update inertia weight (linear decay)\n",
    "current_w = self.pso_w * (self.max_iter - iteration) / self.max_iter\n",
    "# Update hunting coefficient A for MWPA (linear decay)\n",
    "current_A = 2 * (1 - iteration / self.max_iter)\n",
    "for i in range(self.n_agents):\n",
    "# Probabilistically choose which algorithm's update to apply\n",
    "choice = np.random.choice(['ACO', 'PSO+MWPA', 'ABC'], p=self.hybrid_probs)\n",
    "current_pos = self.agents_pos[i]\n",
    "current_vel = self.velocities[i]\n",
    "pbest_pos_i = self.pbest_pos[i]\n",
    "gbest_pos_i = self.gbest_pos # Global best is the alpha wolf/prey\n",
    "if choice == 'PSO+MWPA':\n",
    "# --- PSO + MWPA Velocity Update ---\n",
    "r1, r2 = np.random.rand(self.n_features), np.random.rand(self.n_features) # Random vectors for PSO\n",
    "r3 = np.random.rand() # Random scalar for MWPA D calculation\n",
    "# PSO terms\n",
    "pso_vel_term = self.pso_c1 * r1 * (pbest_pos_i - current_pos) + self.pso_c2 * r2 * (gbest_pos_i - current_pos)\n",
    "# MWPA term (adapted to influence velocity)\n",
    "# Distance to alpha (gbest)\n",
    "D = np.abs(2 * r3 * gbest_pos_i - current_pos)\n",
    "# The abstract equation adds A*D^alpha to velocity. Let's use A * (D**beta)\n",
    "mwpa_vel_term = current_A * (D**self.mwpa_beta) * np.random.uniform(-1, 1, self.n_features) # Add randomness and direction\n",
    "# Combined velocity update\n",
    "new_velocities[i] = current_w * current_vel + pso_vel_term + mwpa_vel_term\n",
    "# Update position\n",
    "new_agents_pos[i] = current_pos + new_velocities[i]\n",
    "elif choice == 'ABC':\n",
    "# --- ABC Search Update ---\n",
    "# Select a random neighbor agent (j != i)\n",
    "if self.n_agents > 1:\n",
    "neighbor_idx = np.random.choice([j for j in range(self.n_agents) if j != i])\n",
    "else:\n",
    "neighbor_idx = i # If only one, compare to itself (no change)\n",
    "phi = np.random.uniform(-1, 1, self.n_features)\n",
    "new_agents_pos[i] = current_pos + phi * (current_pos - self.agents_pos[neighbor_idx])\n",
    "new_velocities[i] = np.zeros_like(current_vel) # Reset velocity after ABC move\n",
    "elif choice == 'ACO':\n",
    "# --- ACO-inspired Update (for continuous space) ---\n",
    "# Use pheromones to bias a random walk or step towards gbest\n",
    "# Probability of moving towards gbest vs random walk could depend on pheromones?\n",
    "# Simple approach: Add a step biased by pheromones and gbest\n",
    "prob = (self.pheromones + 1e-9) / (np.sum(self.pheromones) + 1e-9)\n",
    "# Step direction biased by pheromones (more likely to step in dimensions with high pheromone)\n",
    "biased_random_step = np.random.rand(self.n_features) * prob * 0.1 # Step size scaled by prob\n",
    "# Move towards gbest, scaled by a random factor and potentially pheromones\n",
    "move_towards_gbest = np.random.rand(self.n_features) * (gbest_pos_i - current_pos) * prob * 0.1\n",
    "new_agents_pos[i] = current_pos + biased_random_step + move_towards_gbest\n",
    "new_velocities[i] = np.zeros_like(current_vel) # Reset velocity after ACO move\n",
    "# Apply bounds [0, 1] to positions after update\n",
    "new_agents_pos[i] = np.clip(new_agents_pos[i], 0, 1)\n",
    "# Evaluate fitness of the BINARY mask derived from the new continuous position\n",
    "current_mask = _binarize(new_agents_pos[i])\n",
    "current_fitnesses[i] = feature_fitness(current_mask, self.X_train_val, self.y_train_val, self.X_val, self.y_val, self.alpha_fitness)\n",
    "# --- Update Personal Best (PSO/Hybrid) ---\n",
    "if current_fitnesses[i] > self.pbest_fit[i]:\n",
    "self.pbest_fit[i] = current_fitnesses[i]\n",
    "self.pbest_pos[i] = new_agents_pos[i].copy()\n",
    "# --- Update Trial Count (ABC) ---\n",
    "# If the position improved fitness, reset trial count. Otherwise, increment.\n",
    "# This requires comparing to the fitness *before* the update.\n",
    "# A simpler approach in a hybrid: if fitness improved, reset trials.\n",
    "if current_fitnesses[i] > feature_fitness(_binarize(current_pos), self.X_train_val, self.y_train_val, self.X_val, self.y_val, self.alpha_fitness):\n",
    "self.trials[i] = 0\n",
    "else:\n",
    "self.trials[i] += 1\n",
    "# --- Apply Global Updates (after all agents are updated) ---\n",
    "self.agents_pos = new_agents_pos\n",
    "self.velocities = new_velocities\n",
    "# Update Global Best (PSO/MWPA/Hybrid - based on MAXIMUM fitness)\n",
    "best_current_idx = np.argmax(current_fitnesses)\n",
    "if current_fitnesses[best_current_idx] > self.gbest_fit:\n",
    "self.gbest_fit = current_fitnesses[best_current_idx]\n",
    "self.gbest_pos = self.agents_pos[best_current_idx].copy()\n",
    "self.best_fitness = self.gbest_fit # Update overall best fitness\n",
    "self.best_feature_mask = _binarize(self.gbest_pos).copy() # Update overall best mask\n",
    "# --- ACO Pheromone Update ---\n",
    "# Evaporation\n",
    "self.pheromones *= (1 - self.aco_evap)\n",
    "# Deposit on features in the global best mask\n",
    "if self.best_fitness > -np.inf:\n",
    "self.pheromones[self.best_feature_mask == 1] += self.aco_deposit * self.best_fitness # Deposit proportional to fitness\n",
    "self.pheromones = np.maximum(self.pheromones, 1e-2) # Keep pheromones slightly positive\n",
    "# --- ABC Scout Phase ---\n",
    "# Identify exhausted agents (trials > limit) and replace them\n",
    "scout_indices = np.where(self.trials >= self.limit)[0]\n",
    "for i in scout_indices:\n",
    "# Replace with a new randomly generated position\n",
    "self.agents_pos[i] = np.random.rand(self.n_features)\n",
    "self.velocities[i] = np.zeros(self.n_features) # Reset velocity\n",
    "self.trials[i] = 0 # Reset trial count\n",
    "# Re-evaluate fitness for the new agent and update personal/global bests if needed\n",
    "new_fit = feature_fitness(_binarize(self.agents_pos[i]), self.X_train_val, self.y_train_val, self.X_val, self.y_val, self.alpha_fitness)\n",
    "self.pbest_fit[i] = new_fit # New position is the new personal best\n",
    "self.pbest_pos[i] = self.agents_pos[i].copy()\n",
    "if new_fit > self.gbest_fit:\n",
    "self.gbest_fit = new_fit\n",
    "self.gbest_pos = self.agents_pos[i].copy()\n",
    "self.best_fitness = self.gbest_fit\n",
    "self.best_feature_mask = _binarize(self.gbest_pos).copy()\n",
    "def run(self, X_train_val, y_train_val, X_val, y_val):\n",
    "\"\"\"Runs the hybrid swarm intelligence algorithm for feature selection.\"\"\"\n",
    "self.X_train_val = X_train_val\n",
    "self.y_train_val = y_train_val\n",
    "self.X_val = X_val\n",
    "self.y_val = y_val\n",
    "if self.n_features == 0:\n",
    "print(\"\\nNo features available for selection. Skipping feature selection.\")\n",
    "self.best_feature_mask = np.zeros(0, dtype=int)\n",
    "self.best_fitness = -np.inf\n",
    "self.fitness_history = []\n",
    "self.computational_time = 0\n",
    "return self.best_feature_mask, self.fitness_history, self.computational_time\n",
    "self.initialize_agents()\n",
    "# Ensure initial best fitness is recorded if valid\n",
    "if self.best_fitness > -np.inf:\n",
    "self.fitness_history = [self.best_fitness]\n",
    "else:\n",
    "self.fitness_history = [] # Start empty if no valid initial solution\n",
    "# print(\"\\nStarting Hybrid Swarm Intelligence Feature Selection...\") # Moved print outside\n",
    "start_time = time.time()\n",
    "for iteration in range(self.max_iter):\n",
    "self.update_agents(iteration) # Pass iteration number if needed for parameters (e.g., inertia)\n",
    "# Append current best fitness (could be the same as previous)\n",
    "self.fitness_history.append(self.best_fitness)\n",
    "# print(f\"  Hybrid FS Iter {iteration+1}/{self.max_iter}, Best Fit: {self.best_fitness:.4f}, Selected: {np.sum(self.best_feature_mask)}\") # Uncomment for verbose\n",
    "end_time = time.time()\n",
    "self.computational_time = end_time - start_time\n",
    "# print(\"Feature Selection finished.\") # Moved print outside\n",
    "# print(f\"Best Fitness found: {self.best_fitness:.4f}\") # Moved print outside\n",
    "# print(f\"Number of features selected: {np.sum(self.best_feature_mask)}\") # Moved print outside\n",
    "# print(f\"Computational time: {self.computational_time:.2f} seconds\") # Moved print outside\n",
    "return self.best_feature_mask, self.fitness_history, self.computational_time\n",
    "# --- End of Plausible Hybrid Swarm Intelligence Algorithm for Feature Selection ---\n",
    "else:\n",
    "print(\"\\nSkipping hybrid swarm algorithm definition as data was not loaded or split.\")\n",
    "# Define a dummy class to avoid errors if instantiated\n",
    "class HybridSwarmFeatureSelector:\n",
    "def __init__(self, *args, **kwargs): pass\n",
    "def run(self, *args, **kwargs):\n",
    "print(\"Hybrid selector called but data not loaded.\")\n",
    "return np.array([]), [], 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f148cea",
   "metadata": {},
   "source": [
    "# # 6. Run Feature Selection Experiments\n",
    "#\n",
    "# Run each of the implemented feature selection methods (Individual ACO, PSO, ABC, MWPA, and the Hybrid) on the training/validation data splits.\n",
    "#\n",
    "# Collect the results: the best feature mask found, the convergence history (best fitness per iteration), and the computational time for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb37af",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_results = {}\n",
    "if data_loaded and X_tr.shape > 0:\n",
    "print(\"\\n--- Running Feature Selection Experiments ---\")\n",
    "# Define the methods to run\n",
    "# Map method names to their corresponding functions/classes\n",
    "fs_methods = {\n",
    "\"ACO\": aco_fs,\n",
    "\"PSO\": pso_fs,\n",
    "\"ABC\": abc_fs,\n",
    "\"MWPA\": mwpa_fs,\n",
    "\"Hybrid\": HybridSwarmFeatureSelector # Instantiate the class for hybrid\n",
    "}\n",
    "# Parameters for the runs (can be adjusted)\n",
    "run_params = {\n",
    "\"n_agents\": 30,\n",
    "\"max_iter\": 50, # Reduced iterations for faster example run. Increase for better results.\n",
    "\"alpha_fitness\": 0.05 # Feature penalty weight\n",
    "# Add specific parameters for individual/hybrid methods here if needed\n",
    "# Example for Hybrid: 'pso_w': 0.8, 'aco_evap': 0.05, 'hybrid_probs': [0.4, 0.3, 0.3]\n",
    "}\n",
    "# Loop through each method and run it\n",
    "for name, method in tqdm(fs_methods.items(), desc=\"Running FS Methods\"):\n",
    "print(f\"\\nRunning FS method: {name}\")\n",
    "try:\n",
    "if name == \"Hybrid\":\n",
    "# Instantiate the hybrid class\n",
    "selector = method(n_features=X_tr.shape, **run_params)\n",
    "selected_mask, history, comp_time = selector.run(X_tr, y_tr, X_val, y_val)\n",
    "else:\n",
    "# Run the individual function\n",
    "selected_mask, history, comp_time = method(X_tr, y_tr, X_val, y_val, **run_params)\n",
    "feature_selection_results[name] = {\n",
    "'selected_mask': selected_mask,\n",
    "'num_features': np.sum(selected_mask) if selected_mask is not None else 0,\n",
    "'fitness_history': history,\n",
    "'time': comp_time,\n",
    "'best_fitness': history[-1] if history else -np.inf # Final fitness\n",
    "}\n",
    "print(f\"{name} completed. Selected Features: {feature_selection_results[name]['num_features']}, Final Fitness: {feature_selection_results[name]['best_fitness']:.4f}, Time: {feature_selection_results[name]['time']:.2f}s\")\n",
    "except Exception as e:\n",
    "print(f\"Error running {name}: {e}\")\n",
    "feature_selection_results[name] = {\n",
    "'selected_mask': None,\n",
    "'num_features': 0,\n",
    "'fitness_history': [],\n",
    "'time': 0,\n",
    "'best_fitness': -np.inf,\n",
    "'error': str(e)\n",
    "}\n",
    "print(f\"{name} failed.\")\n",
    "print(\"\\n--- Feature Selection Experiments Complete ---\")\n",
    "# Summarize feature selection results\n",
    "print(\"\\nFeature Selection Summary:\")\n",
    "for name, results in feature_selection_results.items():\n",
    "if 'error' in results:\n",
    "print(f\"  {name}: ERROR - {results['error']}\")\n",
    "else:\n",
    "print(f\"  {name}: Selected Features = {results['num_features']}, Final Fitness = {results['best_fitness']:.4f}, Time = {results['time']:.2f}s\")\n",
    "# Plot convergence curves for all methods\n",
    "plt.figure(figsize=(12, 8))\n",
    "for name, results in feature_selection_results.items():\n",
    "if results['fitness_history']:\n",
    "plt.plot(results['fitness_history'], label=f'{name} (Final Fit: {results[\"best_fitness\"]:.4f})')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Best Fitness\")\n",
    "plt.title(\"Feature Selection Convergence Comparison\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "else:\n",
    "print(\"\\nSkipping feature selection experiments as data was not loaded or split.\")\n",
    "feature_selection_results = {}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6fda1f",
   "metadata": {},
   "source": [
    "# # 7. Model Training\n",
    "#\n",
    "# Train final classifiers (Random Forest, SVM, Neural Networks) using the features selected by **each** feature selection method (Individual ACO, PSO, ABC, MWPA, and Hybrid).\n",
    "#\n",
    "# We will use the combined training and validation set (`X_tr` + `X_val`, `y_tr` + `y_val`) for training the final models. Hyperparameter tuning will be done using cross-validation on this combined set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcde06d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import time\n",
    "final_models = {}\n",
    "final_model_training_time = {}\n",
    "final_model_best_params = {}\n",
    "# Proceed only if feature selection results are available and test data exists\n",
    "if feature_selection_results and X_test_p.shape[0] > 0:\n",
    "print(\"\\n--- Starting Final Model Training ---\")\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "\"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "\"SVM\": SVC(probability=True, random_state=42), # probability=True needed for ROC AUC\n",
    "\"Neural Network\": MLPClassifier(random_state=42, max_iter=500) # Increased max_iter for better convergence\n",
    "}\n",
    "# Hyperparameter tuning distributions (can be adjusted)\n",
    "# Reduced n_iter for faster example run. Increase for better tuning.\n",
    "param_distributions = {\n",
    "\"Random Forest\": {\n",
    "'n_estimators': [50, 100], # Reduced options\n",
    "'max_depth': [10, 20, None], # Reduced options\n",
    "'min_samples_split': [2, 5] # Reduced options\n",
    "},\n",
    "\"SVM\": {\n",
    "'C': [0.1, 1], # Reduced options\n",
    "'gamma': ['scale', 0.1], # Reduced options\n",
    "'kernel': ['rbf']\n",
    "},\n",
    "\"Neural Network\": {\n",
    "'hidden_layer_sizes': [(50,), (100,)], # Reduced options\n",
    "'activation': ['relu'], # Reduced options\n",
    "'solver': ['adam'],\n",
    "'alpha': [0.0001, 0.001] # Reduced options\n",
    "}\n",
    "}\n",
    "# Combine train and validation splits for training the final models\n",
    "X_train_val_combined = np.vstack((X_tr, X_val))\n",
    "y_train_val_combined = pd.concat([y_tr, y_val])\n",
    "# Train models for each feature selection method's result\n",
    "for fs_method_name, fs_results in tqdm(feature_selection_results.items(), desc=\"Training Models per FS Method\"):\n",
    "selected_mask = fs_results.get('selected_mask')\n",
    "if selected_mask is None or np.sum(selected_mask) == 0:\n",
    "print(f\"\\nSkipping model training for {fs_method_name} as no features were selected.\")\n",
    "final_models[fs_method_name] = {clf_name: \"No Features Selected\" for clf_name in classifiers.keys()}\n",
    "final_model_training_time[fs_method_name] = {clf_name: 0 for clf_name in classifiers.keys()}\n",
    "final_model_best_params[fs_method_name] = {clf_name: {} for clf_name in classifiers.keys()}\n",
    "continue\n",
    "num_selected_features = np.sum(selected_mask)\n",
    "print(f\"\\nTraining models using features selected by {fs_method_name} ({num_selected_features} features)...\")\n",
    "# Select features from the combined training+validation data\n",
    "X_train_val_selected = X_train_val_combined[:, np.where(selected_mask == 1)[0]]\n",
    "# Check if selected data is valid for training\n",
    "if X_train_val_selected.shape[0] < 2 or X_train_val_selected.shape[1] == 0:\n",
    "print(f\"  Skipping training for {fs_method_name}: Insufficient data or features ({X_train_val_selected.shape}).\")\n",
    "final_models[fs_method_name] = {clf_name: \"Insufficient Data/Features\" for clf_name in classifiers.keys()}\n",
    "final_model_training_time[fs_method_name] = {clf_name: 0 for clf_name in classifiers.keys()}\n",
    "final_model_best_params[fs_method_name] = {clf_name: {} for clf_name in classifiers.keys()}\n",
    "continue\n",
    "final_models[fs_method_name] = {}\n",
    "final_model_training_time[fs_method_name] = {}\n",
    "final_model_best_params[fs_method_name] = {}\n",
    "# Train each classifier\n",
    "for clf_name, clf_model in tqdm(classifiers.items(), desc=f\"  Training Classifiers for {fs_method_name}\", leave=False):\n",
    "# print(f\"  Training {clf_name}...\") # Use inner tqdm description instead\n",
    "start_time = time.time()\n",
    "# Use RandomizedSearchCV for tuning on the selected features\n",
    "# n_iter controls the number of parameter combinations sampled. Reduce for faster run.\n",
    "# cv=3 or 5 for cross-validation on the combined train+val set\n",
    "# error_score='raise' helps debug issues with parameters\n",
    "random_search = RandomizedSearchCV(\n",
    "clf_model,\n",
    "param_distributions=param_distributions[clf_name],\n",
    "n_iter=3, # Reduced n_iter for faster example run. Increase for better tuning.\n",
    "cv=3,\n",
    "scoring='accuracy',\n",
    "random_state=42,\n",
    "n_jobs=-1, # Use all available cores\n",
    "verbose=0, # Reduce verbosity\n",
    "error_score='raise' # Raise errors instead of ignoring\n",
    ")\n",
    "try:\n",
    "# Fit on the selected features from the combined train+val set\n",
    "random_search.fit(X_train_val_selected, y_train_val_combined)\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "best_model = random_search.best_estimator_\n",
    "best_params_found = random_search.best_params_\n",
    "final_models[fs_method_name][clf_name] = best_model\n",
    "final_model_training_time[fs_method_name][clf_name] = training_time\n",
    "final_model_best_params[fs_method_name][clf_name] = best_params_found\n",
    "# print(f\"    Best CV accuracy for {clf_name}: {random_search.best_score_:.4f}\") # Use inner tqdm description instead\n",
    "# print(f\"    Training time for {clf_name}: {training_time:.2f} seconds\") # Use inner tqdm description instead\n",
    "except Exception as e:\n",
    "print(f\"\\n    Error training {clf_name} for {fs_method_name}: {e}\")\n",
    "print(\"    Skipping evaluation for this model.\")\n",
    "final_models[fs_method_name][clf_name] = \"Training Failed\" # Mark as failed\n",
    "final_model_training_time[fs_method_name][clf_name] = 0\n",
    "final_model_best_params[fs_method_name][clf_name] = {}\n",
    "print(\"\\n--- Final Model Training Complete ---\")\n",
    "else:\n",
    "print(\"\\nSkipping final model training as feature selection results are not available or test data is missing.\")\n",
    "final_models = {}\n",
    "final_model_training_time = {}\n",
    "final_model_best_params = {}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d9f592",
   "metadata": {},
   "source": [
    "# # 8. Model Evaluation\n",
    "#\n",
    "# Evaluate the trained final models on the held-out test set (`X_test_p`, `y_test`) using the features selected by each method.\n",
    "#\n",
    "# Metrics include: Accuracy, Precision, Recall, F1-score, ROC AUC, Confusion Matrix, and False Positive Rate (FPR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Starting Final Model Evaluation on Test Set ---\")\n",
    "final_evaluation_results = {}\n",
    "# Proceed only if final models were trained and test data is available\n",
    "if final_models and X_test_p.shape > 0:\n",
    "for fs_method_name, clf_models in tqdm(final_models.items(), desc=\"Evaluating Models per FS Method\"):\n",
    "# print(f\"\\nEvaluating models trained with features from {fs_method_name}...\") # Use outer tqdm description\n",
    "selected_mask = feature_selection_results.get(fs_method_name, {}).get('selected_mask')\n",
    "if selected_mask is None or np.sum(selected_mask) == 0:\n",
    "# print(f\"  Skipping evaluation for {fs_method_name} as no features were selected.\") # Use outer tqdm description\n",
    "final_evaluation_results[fs_method_name] = {clf_name: \"No Features Selected\" for clf_name in clf_models.keys()}\n",
    "continue\n",
    "# Select features from the test data\n",
    "X_test_selected = X_test_p[:, np.where(selected_mask == 1)]\n",
    "# Check if selected test data is valid for evaluation\n",
    "if X_test_selected.shape == 0 or X_test_selected.shape == 0:\n",
    "print(f\"  Skipping evaluation for {fs_method_name}: Insufficient test data or features ({X_test_selected.shape}).\")\n",
    "final_evaluation_results[fs_method_name] = {clf_name: \"Insufficient Test Data/Features\" for clf_name in clf_models.keys()}\n",
    "continue\n",
    "final_evaluation_results[fs_method_name] = {}\n",
    "for clf_name, model in tqdm(clf_models.items(), desc=f\"  Evaluating Classifiers for {fs_method_name}\", leave=False):\n",
    "if isinstance(model, str): # Check if model training failed\n",
    "# print(f\"  Skipping evaluation for {clf_name} due to status: {model}.\") # Use inner tqdm description\n",
    "final_evaluation_results[fs_method_name][clf_name] = model\n",
    "continue\n",
    "# print(f\"  Evaluating {clf_name}...\") # Use inner tqdm description\n",
    "try:\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_selected)\n",
    "# Get probabilities for ROC AUC (if supported)\n",
    "y_prob = None\n",
    "roc_auc = \"N/A\"\n",
    "try:\n",
    "if hasattr(model, \"predict_proba\"):\n",
    "y_prob = model.predict_proba(X_test_selected)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "elif hasattr(model, \"decision_function\"): # For SVM with linear kernel\n",
    "y_prob = model.decision_function(X_test_selected)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "except Exception as e:\n",
    "# print(f\"  Could not calculate ROC AUC for {clf_name}: {e}\") # Uncomment for debugging\n",
    "y_prob = None\n",
    "roc_auc = \"Error\"\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, output_dict=True, zero_division=0) # zero_division=0 to avoid warnings/errors\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Calculate FPR: FP / (FP + TN)\n",
    "# cm = [[TN, FP], [FN, TP]]\n",
    "if cm.shape == (2, 2):\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "fpr = FP / (FP + TN) if (FP + TN) != 0 else 0\n",
    "else:\n",
    "# Handle cases where confusion matrix might not be 2x2 (e.g., only one class predicted)\n",
    "# print(f\"  Warning: Confusion matrix for {clf_name} is not 2x2: {cm.shape}. Cannot calculate FPR easily.\") # Uncomment for debugging\n",
    "fpr = \"N/A\"\n",
    "final_evaluation_results[fs_method_name][clf_name] = {\n",
    "'accuracy': accuracy,\n",
    "'report': report,\n",
    "'confusion_matrix': cm,\n",
    "'roc_auc': roc_auc,\n",
    "'fpr': fpr,\n",
    "'num_features': np.sum(selected_mask)\n",
    "}\n",
    "# Print results for this classifier (optional, can rely on summary table)\n",
    "# print(f\"    Accuracy: {accuracy:.4f}\")\n",
    "# print(f\"    FPR: {fpr:.4f}\" if isinstance(fpr, float) else f\"FPR: {fpr}\")\n",
    "# print(f\"    ROC AUC: {roc_auc:.4f}\" if isinstance(roc_auc, float) else f\"ROC AUC: {roc_auc}\")\n",
    "# print(\"\\nClassification Report:\") # Uncomment for verbose\n",
    "# print(classification_report(y_test, y_pred, zero_division=0))\n",
    "# print(\"\\nConfusion Matrix:\") # Uncomment for verbose\n",
    "# print(cm)\n",
    "# Plot ROC curve if probabilities are available and ROC AUC was calculated\n",
    "if y_prob is not None and isinstance(roc_auc, float):\n",
    "try:\n",
    "fpr_curve, tpr_curve, _ = roc_curve(y_test, y_prob)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_curve, tpr_curve, label=f'{clf_name} (AUC = {roc_auc:.4f})')\n",
    "plt.plot(,, 'k--') # Random guess line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC Curve - {fs_method_name} + {clf_name}')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "except Exception as e:\n",
    "print(f\"    Could not plot ROC curve for {clf_name}: {e}\")\n",
    "except Exception as e:\n",
    "print(f\"\\n    Error during evaluation of {clf_name} for {fs_method_name}: {e}\")\n",
    "final_evaluation_results[fs_method_name][clf_name] = \"Evaluation Failed\"\n",
    "print(\"\\n--- Final Model Evaluation Complete ---\")\n",
    "# Summarize results across all FS methods and classifiers\n",
    "print(\"\\n--- Summary of Test Set Results ---\")\n",
    "summary_data = []\n",
    "for fs_method_name, clf_results in final_evaluation_results.items():\n",
    "for clf_name, metrics in clf_results.items():\n",
    "if isinstance(metrics, str):\n",
    "summary_data.append({\n",
    "'FS Method': fs_method_name,\n",
    "'Classifier': clf_name,\n",
    "'Status': metrics,\n",
    "'Num Features': feature_selection_results.get(fs_method_name, {}).get('num_features', 0),\n",
    "'Accuracy': np.nan, 'FPR': np.nan, 'ROC AUC': np.nan,\n",
    "'Precision (Attack)': np.nan, 'Recall (Attack)': np.nan, 'F1-Score (Attack)': np.nan,\n",
    "'FS Time (s)': feature_selection_results.get(fs_method_name, {}).get('time', np.nan),\n",
    "'Train Time (s)': final_model_training_time.get(fs_method_name, {}).get(clf_name, np.nan)\n",
    "})\n",
    "else:\n",
    "summary_data.append({\n",
    "'FS Method': fs_method_name,\n",
    "'Classifier': clf_name,\n",
    "'Status': 'Success',\n",
    "'Num Features': metrics.get('num_features', np.nan),\n",
    "'Accuracy': metrics.get('accuracy', np.nan),\n",
    "'FPR': metrics.get('fpr', np.nan) if isinstance(metrics.get('fpr'), float) else np.nan,\n",
    "'ROC AUC': metrics.get('roc_auc', np.nan) if isinstance(metrics.get('roc_auc'), float) else np.nan,\n",
    "'Precision (Attack)': metrics['report'].get('1', {}).get('precision', np.nan),\n",
    "'Recall (Attack)': metrics['report'].get('1', {}).get('recall', np.nan),\n",
    "'F1-Score (Attack)': metrics['report'].get('1', {}).get('f1-score', np.nan),\n",
    "'FS Time (s)': feature_selection_results.get(fs_method_name, {}).get('time', np.nan),\n",
    "'Train Time (s)': final_model_training_time.get(fs_method_name, {}).get(clf_name, np.nan)\n",
    "})\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string()) # Print full dataframe\n",
    "else:\n",
    "print(\"\\nSkipping final model evaluation as models were not trained or test data is not available.\")\n",
    "summary_df = pd.DataFrame() # Ensure summary_df exists\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01eef3f",
   "metadata": {},
   "source": [
    "# # 9. Implement Plausible Hybrid Swarm Optimizer for Benchmarks\n",
    "#\n",
    "# Implement a plausible hybrid ACO+PSO+ABC+MWPA algorithm for continuous optimization benchmark functions.\n",
    "#\n",
    "# - This class `HybridSwarmOptimizer` manages the population and the iteration process for continuous variables.\n",
    "# - It minimizes the objective function.\n",
    "# - The `update_agents` method implements the hybridization logic, attempting to combine the update rules for continuous space. This implementation uses a probabilistic approach where each agent applies one of the component-inspired updates (ACO, PSO+MWPA, ABC).\n",
    "#\n",
    "# **Note:** This is a *plausible interpretation* of how these algorithms could be hybridized for continuous optimization, inspired by the abstract's equation. Your specific novel algorithm might differ. You should replace the logic inside `initialize_agents` and `update_agents` with your precise implementation if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050b8c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "import time\n",
    "# Define benchmark functions (to be minimized)\n",
    "def sphere(x):\n",
    "\"\"\"Sphere function: f(x) = sum(x_i^2). Global minimum 0 at x = [0, ..., 0].\"\"\"\n",
    "x = np.asarray(x) # Ensure x is numpy array\n",
    "return np.sum(x**2)\n",
    "def rastrigin(x):\n",
    "\"\"\"Rastrigin function: f(x) = 10*n + sum(x_i^2 - 10*cos(2*pi*x_i)). Global minimum 0 at x = [0, ..., 0].\"\"\"\n",
    "x = np.asarray(x) # Ensure x is numpy array\n",
    "n = len(x)\n",
    "return 10 * n + np.sum(x**2 - 10 * np.cos(2 * np.pi * x))\n",
    "def rosenbrock(x):\n",
    "\"\"\"Rosenbrock function: f(x) = sum(100*(x_{i+1} - x_i^2)^2 + (x_i - 1)^2). Global minimum 0 at x = [1, ..., 1].\"\"\"\n",
    "x = np.asarray(x) # Ensure x is numpy array\n",
    "# Ensure x has at least 2 dimensions for the calculation\n",
    "if len(x) < 2:\n",
    "# Handle 1D case or return infinity/error - Rosenbrock is typically multi-dimensional\n",
    "# Returning a large value indicates it's not the minimum\n",
    "return np.sum((x - 1)**2) if len(x) == 1 else np.inf\n",
    "return np.sum(100.0 * (x[1:] - x[:-1]**2.0)**2.0 + (x[:-1] - 1)**2.0)\n",
    "# Define search space bounds for the functions (example bounds)\n",
    "# Sphere and Rastrigin are often evaluated on [-5.12, 5.12]\n",
    "# Rosenbrock is often evaluated on [-5, 10] or [-2.048, 2.048]\n",
    "n_dimensions_benchmark = 10 # Example number of dimensions for benchmark functions\n",
    "bounds_sphere = [(-5.12, 5.12)] * n_dimensions_benchmark\n",
    "bounds_rastrigin = [(-5.12, 5.12)] * n_dimensions_benchmark\n",
    "bounds_rosenbrock = [(-2.048, 2.048)] * n_dimensions_benchmark\n",
    "# --- Plausible Hybrid Swarm Algorithm for Minimization ---\n",
    "class HybridSwarmOptimizer:\n",
    "def __init__(self, objective_func, bounds, n_agents=50, max_iter=100,\n",
    "pso_w=0.7, pso_c1=1.5, pso_c2=1.5, aco_evap=0.1, aco_deposit=0.1,\n",
    "abc_limit=5, mwpa_beta=1.5, hybrid_probs=[0.33, 0.33, 0.34]): # Probabilities for [ACO, PSO+MWPA, ABC]\n",
    "\"\"\"\n",
    "Initializes the hybrid swarm intelligence optimizer for continuous problems.\n",
    "Uses a probabilistic approach to apply component-inspired updates.\n",
    "\"\"\"\n",
    "self.objective_func = objective_func\n",
    "self.bounds = np.array(bounds) # Convert bounds to numpy array\n",
    "self.n_agents = n_agents\n",
    "self.max_iter = max_iter\n",
    "self.n_dimensions = len(bounds)\n",
    "# Algorithm parameters\n",
    "self.pso_w = pso_w\n",
    "self.pso_c1 = pso_c1\n",
    "self.pso_c2 = pso_c2\n",
    "self.aco_evap = aco_evap\n",
    "self.aco_deposit = aco_deposit\n",
    "self.abc_limit = abc_limit\n",
    "self.mwpa_beta = mwpa_beta\n",
    "self.hybrid_probs = hybrid_probs # Probabilities for selecting update type\n",
    "# Agent state (continuous positions)\n",
    "self.agents_pos = np.random.uniform(self.bounds[:, 0], self.bounds[:, 1], size=(self.n_agents, self.n_dimensions))\n",
    "self.velocities = np.zeros_like(self.agents_pos) # For PSO part\n",
    "self.pbest_pos = self.agents_pos.copy()\n",
    "self.pbest_value = np.full(self.n_agents, np.inf)\n",
    "# Global best (shared)\n",
    "self.gbest_pos = np.random.uniform(self.bounds[:, 0], self.bounds[:, 1], size=self.n_dimensions) # Initialize randomly\n",
    "self.gbest_value = self.objective_func(self.gbest_pos) # Evaluate initial best\n",
    "self.best_position = self.gbest_pos.copy() # Overall best position\n",
    "self.best_value = self.gbest_value # Overall best value\n",
    "# ACO components (pheromone trail - adapted for continuous space, e.g., on regions or best paths)\n",
    "# A simple adaptation: pheromones on dimensions, influencing step size/direction\n",
    "self.pheromones = np.ones(self.n_dimensions) * 0.1\n",
    "# ABC components (trial counts for scout phase)\n",
    "self.trials = np.zeros(self.n_agents, dtype=int)\n",
    "# MWPA components (alpha wolf is the global best)\n",
    "# Hunting coefficient A will be calculated per iteration/agent\n",
    "self.history = [self.best_value] # To track convergence\n",
    "self.computational_time = 0 # To track time\n",
    "print(f\"HybridSwarmOptimizer initialized for {objective_func.__name__}.\")\n",
    "def initialize_agents(self):\n",
    "\"\"\"\n",
    "Initialize the population of agents (positions) and algorithm-specific components.\n",
    "Agents should be initialized within the specified bounds.\n",
    "\"\"\"\n",
    "# Initialize agents randomly within bounds\n",
    "self.agents_pos = np.random.uniform(\n",
    "self.bounds[:, 0],\n",
    "self.bounds[:, 1],\n",
    "size=(self.n_agents, self.n_dimensions)\n",
    ")\n",
    "self.velocities = np.zeros_like(self.agents_pos) # For PSO part\n",
    "self.pbest_pos = self.agents_pos.copy()\n",
    "self.pbest_value = np.full(self.n_agents, np.inf)\n",
    "# Initialize pheromones\n",
    "self.pheromones = np.ones(self.n_dimensions) * 0.1\n",
    "# Initialize trial counts for ABC\n",
    "self.trials = np.zeros(self.n_agents, dtype=int)\n",
    "# Evaluate initial population to set initial personal and global bests\n",
    "initial_values = [self.objective_func(pos) for pos in self.agents_pos]\n",
    "# Find initial best (MINIMIZING value)\n",
    "best_initial_idx = np.argmin(initial_values)\n",
    "self.gbest_value = initial_values[best_initial_idx]\n",
    "self.gbest_pos = self.agents_pos[best_initial_idx].copy()\n",
    "self.best_value = self.gbest_value\n",
    "self.best_position = self.gbest_pos.copy()\n",
    "self.pbest_value = np.array(initial_values)\n",
    "def update_agents(self, iteration):\n",
    "\"\"\"\n",
    "Perform one iteration of the hybrid swarm intelligence algorithm for minimization.\n",
    "Applies component-inspired updates probabilistically to each agent.\n",
    "\"\"\"\n",
    "new_agents_pos = self.agents_pos.copy()\n",
    "new_velocities = self.velocities.copy()\n",
    "current_values = np.full(self.n_agents, np.inf) # To store values of updated agents\n",
    "# Update inertia weight (linear decay)\n",
    "current_w = self.pso_w * (self.max_iter - iteration) / self.max_iter\n",
    "# Update hunting coefficient A for MWPA (linear decay)\n",
    "current_A = 2 * (1 - iteration / self.max_iter)\n",
    "for i in range(self.n_agents):\n",
    "# Probabilistically choose which algorithm's update to apply\n",
    "choice = np.random.choice(['ACO', 'PSO+MWPA', 'ABC'], p=self.hybrid_probs)\n",
    "current_pos = self.agents_pos[i]\n",
    "current_vel = self.velocities[i]\n",
    "pbest_pos_i = self.pbest_pos[i]\n",
    "gbest_pos_i = self.gbest_pos # Global best is the alpha wolf/prey\n",
    "if choice == 'PSO+MWPA':\n",
    "# --- PSO + MWPA Velocity Update (based on abstract equation form) ---\n",
    "r1, r2 = np.random.rand(self.n_dimensions), np.random.rand(self.n_dimensions) # Random vectors for PSO\n",
    "r3 = np.random.rand() # Random scalar for MWPA D calculation\n",
    "# PSO terms\n",
    "pso_vel_term = self.pso_c1 * r1 * (pbest_pos_i - current_pos) + self.pso_c2 * r2 * (gbest_pos_i - current_pos)\n",
    "# MWPA term (adapted from A*D^beta, added to velocity)\n",
    "# Distance to alpha (gbest)\n",
    "D = np.abs(2 * r3 * gbest_pos_i - current_pos)\n",
    "# The abstract equation adds A*D^alpha to velocity. Let's use A * (D**beta)\n",
    "mwpa_vel_term = current_A * (D**self.mwpa_beta) * np.random.uniform(-1, 1, self.n_dimensions) # Add randomness and direction\n",
    "# Combined velocity update\n",
    "new_velocities[i] = current_w * current_vel + pso_vel_term + mwpa_vel_term\n",
    "# Update position\n",
    "new_agents_pos[i] = current_pos + new_velocities[i]\n",
    "elif choice == 'ABC':\n",
    "# --- ABC Search Update ---\n",
    "# Select a random neighbor agent (j != i)\n",
    "if self.n_agents > 1:\n",
    "neighbor_idx = np.random.choice([j for j in range(self.n_agents) if j != i])\n",
    "else:\n",
    "neighbor_idx = i # If only one, compare to itself (no change)\n",
    "phi = np.random.uniform(-1, 1, self.n_dimensions)\n",
    "new_agents_pos[i] = current_pos + phi * (current_pos - self.agents_pos[neighbor_idx])\n",
    "new_velocities[i] = np.zeros_like(current_vel) # Reset velocity after ABC move\n",
    "elif choice == 'ACO':\n",
    "# --- ACO-inspired Update (for continuous space) ---\n",
    "# Use pheromones to bias a random walk or step towards gbest\n",
    "# Probability of moving towards gbest vs random walk could depend on pheromones?\n",
    "# Simple approach: Add a step biased by pheromones and gbest\n",
    "prob = (self.pheromones + 1e-9) / (np.sum(self.pheromones) + 1e-9)\n",
    "# Step direction biased by pheromones (more likely to step in dimensions with high pheromone)\n",
    "biased_random_step = np.random.rand(self.n_dimensions) * prob * (self.bounds[:,1] - self.bounds[:,0]) * 0.01 # Step size scaled by prob and bounds range\n",
    "# Move towards gbest, scaled by a random factor and potentially pheromones\n",
    "move_towards_gbest = np.random.rand(self.n_dimensions) * (gbest_pos_i - current_pos) * prob * 0.01\n",
    "new_agents_pos[i] = current_pos + biased_random_step + move_towards_gbest\n",
    "new_velocities[i] = np.zeros_like(current_vel) # Reset velocity after ACO move\n",
    "# Apply bounds to positions after update\n",
    "new_agents_pos[i] = np.clip(new_agents_pos[i], self.bounds[:, 0], self.bounds[:, 1])\n",
    "# Evaluate value of the new continuous position\n",
    "current_values[i] = self.objective_func(new_agents_pos[i])\n",
    "# --- Update Personal Best (PSO/Hybrid) ---\n",
    "# MINIMIZING value\n",
    "if current_values[i] < self.pbest_value[i]:\n",
    "self.pbest_value[i] = current_values[i]\n",
    "self.pbest_pos[i] = new_agents_pos[i].copy()\n",
    "# --- Update Trial Count (ABC) ---\n",
    "# If the position improved value, reset trial count. Otherwise, increment.\n",
    "# This requires comparing to the value *before* the update.\n",
    "# A simpler approach in a hybrid: if value improved, reset trials.\n",
    "if current_values[i] < self.objective_func(current_pos):\n",
    "self.trials[i] = 0\n",
    "else:\n",
    "self.trials[i] += 1\n",
    "# --- Apply Global Updates (after all agents are updated) ---\n",
    "self.agents_pos = new_agents_pos\n",
    "self.velocities = new_velocities\n",
    "# Update Global Best (PSO/MWPA/Hybrid - based on MINIMIZING value)\n",
    "best_current_idx = np.argmin(current_values)\n",
    "if current_values[best_current_idx] < self.gbest_value:\n",
    "self.gbest_value = current_values[best_current_idx]\n",
    "self.gbest_pos = self.agents_pos[best_current_idx].copy()\n",
    "self.best_value = self.gbest_value # Update overall best value\n",
    "self.best_position = self.gbest_pos.copy() # Update overall best position\n",
    "# --- ACO Pheromone Update ---\n",
    "# Evaporation\n",
    "self.pheromones *= (1 - self.aco_evap)\n",
    "# Deposit pheromone based on the global best position (e.g., deposit more on dimensions close to gbest)\n",
    "# A simple approach: deposit inversely proportional to distance from gbest (within bounds)\n",
    "# Normalize distance to be between 0 and 1\n",
    "range_bounds = self.bounds[:, 1] - self.bounds[:, 0]\n",
    "normalized_distance_to_gbest = np.abs(self.gbest_pos - self.bounds[:, 0]) / range_bounds\n",
    "# Deposit more where normalized distance is small (closer to one bound, assuming gbest is near an optimum)\n",
    "# Or deposit more where the position is \"good\" - e.g., close to the center if optimum is central, or near bounds if optimum is there.\n",
    "# A simpler approach: deposit based on how \"good\" the gbest position is in each dimension (e.g., closer to 0 for Sphere/Rastrigin, closer to 1 for Rosenbrock)\n",
    "# Let's deposit based on the inverse of the absolute value of gbest position (for functions like Sphere/Rastrigin where optimum is 0)\n",
    "# This is a very simplified continuous ACO pheromone update.\n",
    "deposit_amount_per_dim = self.aco_deposit / (np.abs(self.gbest_pos) + 1e-9) # Avoid division by zero\n",
    "deposit_amount_per_dim = np.clip(deposit_amount_per_dim, 0, 1) # Clip deposit amount\n",
    "self.pheromones += deposit_amount_per_dim # Add deposit\n",
    "self.pheromones = np.maximum(self.pheromones, 1e-2) # Keep pheromones slightly positive\n",
    "# --- ABC Scout Phase ---\n",
    "# Identify exhausted agents (trials > limit) and replace them\n",
    "scout_indices = np.where(self.trials >= self.limit)[0]\n",
    "for i in scout_indices:\n",
    "# Replace with a new randomly generated position within bounds\n",
    "self.agents_pos[i] = np.random.uniform(self.bounds[:, 0], self.bounds[:, 1], size=self.n_dimensions)\n",
    "self.velocities[i] = np.zeros(self.n_dimensions) # Reset velocity\n",
    "self.trials[i] = 0 # Reset trial count\n",
    "# Re-evaluate value for the new agent and update personal/global bests if needed\n",
    "new_value = self.objective_func(self.agents_pos[i])\n",
    "self.pbest_value[i] = new_value # New position is the new personal best\n",
    "self.pbest_pos[i] = self.agents_pos[i].copy()\n",
    "if new_value < self.gbest_value:\n",
    "self.gbest_value = new_value\n",
    "self.gbest_pos = self.agents_pos[i].copy()\n",
    "self.best_value = self.gbest_value\n",
    "self.best_position = self.gbest_pos.copy()\n",
    "def run(self):\n",
    "\"\"\"Runs the hybrid swarm intelligence algorithm for minimization.\"\"\"\n",
    "if self.n_dimensions == 0:\n",
    "print(f\"\\nNo dimensions defined for {self.objective_func.__name__}. Skipping benchmark.\")\n",
    "self.best_position = np.array([])\n",
    "self.best_value = np.inf\n",
    "self.history = []\n",
    "self.computational_time = 0\n",
    "return self.best_position, self.best_value, self.history, self.computational_time\n",
    "self.initialize_agents()\n",
    "self.history = [self.best_value] # Start history with initial best\n",
    "# print(f\"\\nStarting Hybrid Swarm Optimization for {self.objective_func.__name__}...\") # Moved print outside\n",
    "start_time = time.time()\n",
    "for iteration in range(self.max_iter):\n",
    "self.update_agents(iteration) # Pass iteration number if needed for parameters (e.g., inertia)\n",
    "# Append current best value (could be the same as previous)\n",
    "self.history.append(self.best_value)\n",
    "# print(f\"  Hybrid Bench Iter {iteration+1}/{self.max_iter}, Best Value: {self.best_value:.4e}\") # Uncomment for verbose\n",
    "end_time = time.time()\n",
    "self.computational_time = end_time - start_time\n",
    "# print(f\"Optimization finished for {self.objective_func.__name__}.\") # Moved print outside\n",
    "# print(f\"Best Value found: {self.best_value:.4e}\") # Moved print outside\n",
    "# print(f\"Computational time: {self.computational_time:.2f} seconds\") # Moved print outside\n",
    "return self.best_position, self.best_value, self.history, self.computational_time\n",
    "# --- End of Plausible Hybrid Swarm Algorithm for Minimization ---\n",
    "else:\n",
    "print(\"\\nSkipping hybrid swarm optimizer definition as data was not loaded.\")\n",
    "# Define a dummy class to avoid errors if instantiated\n",
    "class HybridSwarmOptimizer:\n",
    "def __init__(self, *args, **kwargs): pass\n",
    "def run(self, *args, **kwargs):\n",
    "print(\"Hybrid optimizer called but data not loaded.\")\n",
    "return np.array([]), np.inf, [], 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009a693b",
   "metadata": {},
   "source": [
    "# # 10. Benchmark Function Analysis\n",
    "#\n",
    "# Evaluate the performance of the hybrid swarm intelligence algorithm on standard optimization benchmark functions like Sphere, Rastrigin, and Rosenbrock. This helps assess its global search and convergence capabilities independently of the feature selection problem.\n",
    "#\n",
    "# **Concept:**\n",
    "# - Define the benchmark functions (mathematical functions with known global minima).\n",
    "# - Run the hybrid algorithm (`HybridSwarmOptimizer`) on each benchmark function and track the convergence towards the known minimum.\n",
    "# - Measure computational efficiency.\n",
    "# - **For comparison (Optional, requires implementing individual continuous algorithms):** Run individual continuous ACO, PSO, ABC, and MWPA algorithms on the same benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6d2ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define benchmark functions (already defined in Step 9)\n",
    "# sphere, rastrigin, rosenbrock\n",
    "# Define search space bounds (already defined in Step 9)\n",
    "# bounds_sphere, bounds_rastrigin, bounds_rosenbrock, n_dimensions_benchmark\n",
    "# Run optimization on benchmark functions using the HybridSwarmOptimizer\n",
    "benchmark_results = {}\n",
    "benchmark_bounds = {\n",
    "'Sphere': bounds_sphere,\n",
    "'Rastrigin': bounds_rastrigin,\n",
    "'Rosenbrock': bounds_rosenbrock\n",
    "}\n",
    "if n_dimensions_benchmark > 0:\n",
    "print(\"\\n--- Running Benchmark Function Analysis (Hybrid) ---\")\n",
    "# Parameters for benchmark runs (can be adjusted)\n",
    "bench_run_params = {\n",
    "\"n_agents\": 30,\n",
    "\"max_iter\": 100, # More iterations for optimization benchmarks\n",
    "# Add specific parameters for the hybrid optimizer here if needed\n",
    "}\n",
    "for name, func in tqdm(benchmark_bounds.items(), desc=\"Running Benchmarks\"):\n",
    "bounds = benchmark_bounds[name]\n",
    "if len(bounds) == 0:\n",
    "print(f\"  Skipping {name}: Bounds not defined.\")\n",
    "benchmark_results[name] = {'best': np.inf, 'hist': [], 'time': 0, 'status': 'No Bounds'}\n",
    "continue\n",
    "print(f\"\\nRunning Hybrid Optimizer on {name}...\")\n",
    "try:\n",
    "optimizer = HybridSwarmOptimizer(func, bounds, **bench_run_params)\n",
    "sol, val, hist, dt = optimizer.run()\n",
    "benchmark_results[name] = {'best': val, 'hist': hist, 'time': dt, 'status': 'Success'}\n",
    "print(f\"{name} completed. Best Value: {val:.4e}, Time: {dt:.2f}s\")\n",
    "except Exception as e:\n",
    "print(f\"Error running Hybrid Optimizer on {name}: {e}\")\n",
    "benchmark_results[name] = {'best': np.inf, 'hist': [], 'time': 0, 'status': f'Error: {e}'}\n",
    "print(f\"{name} failed.\")\n",
    "print(\"\\n--- Benchmark Function Analysis Complete ---\")\n",
    "# Plot benchmark convergence\n",
    "plt.figure(figsize=(12, 8))\n",
    "for name, res in benchmark_results.items():\n",
    "if res['hist']:\n",
    "plt.plot(res['hist'], label=f'{name} (Best: {res[\"best\"]:.4e})')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Best Objective Function Value\")\n",
    "plt.title(\"Hybrid Swarm Intelligence Convergence on Benchmark Functions\")\n",
    "plt.yscale('log') # Use log scale for better visualization of convergence\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# Summarize benchmark results\n",
    "print(\"\\nBenchmark Summary (Hybrid):\")\n",
    "bench_summary_data = []\n",
    "for name, res in benchmark_results.items():\n",
    "bench_summary_data.append({\n",
    "'Function': name,\n",
    "'Status': res.get('status', 'Success'),\n",
    "'Best Value': res['best'],\n",
    "'Time (s)': res['time']\n",
    "})\n",
    "bench_summary_df = pd.DataFrame(bench_summary_data)\n",
    "print(bench_summary_df.to_string())\n",
    "else:\n",
    "print(\"\\nSkipping benchmark function analysis as dimensions are not defined.\")\n",
    "benchmark_results = {}\n",
    "bench_summary_df = pd.DataFrame()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10c8c66",
   "metadata": {},
   "source": [
    "# # 11. Component-wise Analysis\n",
    "#\n",
    "# Study the impact of different components and parameters of the hybrid algorithm, as suggested by the abstract (inertia weight tuning, predatory impact, crossover strategy).\n",
    "#\n",
    "# **Concept:**\n",
    "# - Run your custom hybrid algorithm implementations (from Steps 5 and 9) multiple times with different configurations.\n",
    "# - Configurations could involve:\n",
    "#     - Varying key parameters (e.g., PSO inertia weight strategy, MWPA parameters, ACO parameters, ABC parameters).\n",
    "#     - Testing different hybridization strategies (if you designed multiple ways to combine the algorithms).\n",
    "# - Collect results for each configuration:\n",
    "#     - For Feature Selection: Final classification metrics (Accuracy, FPR, etc. from Step 8 using a fixed classifier), number of selected features, convergence history, computational time.\n",
    "#     - For Benchmark Functions: Final best objective value, convergence history, computational time.\n",
    "# - Compare the results to understand the contribution and sensitivity of different components and parameters.\n",
    "#\n",
    "# **Implementation Notes:**\n",
    "# - This requires implementing the logic within your `HybridSwarmFeatureSelector` and `HybridSwarmOptimizer` classes to allow different components/strategies to be enabled or parameterized via the `**kwargs` in their `__init__` and potentially parameters passed to `update_agents`.\n",
    "# - Then, write code to loop through different configurations, run the algorithm, collect results, and compare them.\n",
    "# - You would also ideally implement individual continuous versions of ACO, PSO, ABC, and MWPA to compare against the hybrid on benchmark functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae70f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Component-wise Analysis (Requires Running Configurable Hybrid) ---\n",
    "print(\"\\n--- Component-wise Analysis ---\")\n",
    "print(\"This section requires running experiments with variations of the hybrid algorithm.\")\n",
    "print(\"You need to modify the HybridSwarmFeatureSelector and HybridSwarmOptimizer classes\")\n",
    "print(\"to accept parameters that control component behavior and hybridization strategy.\")\n",
    "print(\"Then, define different configurations and run the algorithms.\")\n",
    "# Example: Outline of how you might define configurations and run experiments\n",
    "# analysis_configs_fs = [\n",
    "#     {'name': 'Hybrid (Default)', 'n_agents': 30, 'max_iter': 50, 'hybrid_probs': [0.33, 0.33, 0.34]},\n",
    "#     {'name': 'Hybrid (More PSO+MWPA)', 'n_agents': 30, 'max_iter': 50, 'hybrid_probs': [0.1, 0.6, 0.3]},\n",
    "#     {'name': 'Hybrid (Adaptive Inertia)', 'n_agents': 30, 'max_iter': 50, 'pso_w_strategy': 'adaptive'}, # Requires implementing 'pso_w_strategy' in HybridSwarmFeatureSelector\n",
    "#     # Add configurations to test MWPA parameters, ACO parameters, ABC parameters, etc.\n",
    "# ]\n",
    "# analysis_results_fs = {}\n",
    "# if data_loaded and X_tr.shape[0] > 0 and X_test_p.shape[0] > 0:\n",
    "#     print(\"\\nStarting Component-wise Analysis (Feature Selection)...\")\n",
    "#     # You would loop through analysis_configs_fs and run HybridSwarmFeatureSelector for each\n",
    "#     # Then evaluate the resulting feature masks using a fixed classifier (e.g., the best RF from Step 7)\n",
    "#     # and compare metrics like accuracy, FPR, num_features, and time.\n",
    "#     print(\"Placeholder: Implement the loop and evaluation for FS component analysis.\")\n",
    "# else:\n",
    "#      print(\"\\nSkipping Component-wise Analysis (Feature Selection) as data is missing.\")\n",
    "# analysis_configs_bench = [\n",
    "#      {'name': 'Hybrid (Default)', 'n_agents': 30, 'max_iter': 100, 'hybrid_probs': [0.33, 0.33, 0.34]},\n",
    "#      {'name': 'Hybrid (More Predation)', 'n_agents': 30, 'max_iter': 100, 'mwpa_beta': 2.0}, # Requires implementing 'mwpa_beta' in HybridSwarmOptimizer\n",
    "#      {'name': 'PSO Only (for comparison)', 'n_agents': 30, 'max_iter': 100, 'hybrid_probs': [0, 1, 0]}, # Example: effectively run PSO+MWPA only\n",
    "#      # Add configurations to test other parameters or compare to individual algorithms\n",
    "# ]\n",
    "# analysis_results_bench = {}\n",
    "# if n_dimensions_benchmark > 0:\n",
    "#     print(\"\\nStarting Component-wise Analysis (Benchmark Functions)...\")\n",
    "#     # You would loop through analysis_configs_bench and run HybridSwarmOptimizer for each on a benchmark function (e.g., Sphere)\n",
    "#     # Then compare metrics like best value found, convergence history, and time.\n",
    "#     print(\"Placeholder: Implement the loop and evaluation for Benchmark component analysis.\")\n",
    "# else:\n",
    "#      print(\"\\nSkipping Component-wise Analysis (Benchmark Functions) as dimensions are not defined.\")\n",
    "print(\"\\nComponent-wise Analysis requires implementing the configurable hybrid algorithm and running experiments here.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0200e8b6",
   "metadata": {},
   "source": [
    "# # 12. Presentation and Demonstration\n",
    "#\n",
    "# Use this Jupyter Notebook and visualizations to present the methodology, results, and analysis, following the structure outlined in the plan and abstract.\n",
    "#\n",
    "# - Structure the notebook logically (as done here).\n",
    "# - Use markdown cells for explanations of each step, the algorithms, the hybrid strategy (once implemented), and the results.\n",
    "# - Use code cells for implementation and execution.\n",
    "# - Include plots for:\n",
    "#     - Hybrid algorithm convergence (feature selection fitness over iterations) - Done in Step 6.\n",
    "#     - Hybrid algorithm convergence (benchmark function value over iterations) - Done in Step 10.\n",
    "#     - ROC curves for the final classifiers - Done in Step 8.\n",
    "#     - Comparison of evaluation metrics (Accuracy, FPR, F1-score, etc.) across different classifiers and different feature selection methods.\n",
    "#     - (If implemented) Comparison plots from the component-wise analysis (e.g., convergence curves for different configurations, bar plots of final metrics/values).\n",
    "# - Document the full workflow from data acquisition to final evaluation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0efc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook itself serves as the presentation structure.\n",
    "# Ensure all previous sections are clear, well-commented, and include relevant visualizations.\n",
    "# Example: Visualizing comparison of final evaluation metrics from Step 8\n",
    "if not summary_df.empty:\n",
    "print(\"\\n--- Visualizing Final Model Evaluation Results ---\")\n",
    "# Filter for successful runs\n",
    "success_df = summary_df[summary_df['Status'] == 'Success'].copy()\n",
    "if not success_df.empty:\n",
    "# Pivot the table for easier plotting\n",
    "# We'll plot metrics for each Classifier, grouped by FS Method\n",
    "metrics_to_plot = ['Accuracy', 'FPR', 'F1-Score (Attack)', 'Num Features', 'FS Time (s)', 'Train Time (s)']\n",
    "for metric in metrics_to_plot:\n",
    "if metric in success_df.columns:\n",
    "plt.figure(figsize=(14, 7))\n",
    "# Create a bar plot for the metric, with FS Method and Classifier on the x-axis\n",
    "# Use seaborn for better grouping\n",
    "sns.barplot(data=success_df, x='FS Method', y=metric, hue='Classifier', palette='viridis')\n",
    "plt.title(f'{metric} Comparison by Feature Selection Method and Classifier')\n",
    "plt.ylabel(metric)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Classifier', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "else:\n",
    "print(f\"Warning: Metric '{metric}' not found in summary data.\")\n",
    "else:\n",
    "print(\"No successful evaluation results to plot.\")\n",
    "# Example: Visualizing comparison of benchmark results from Step 10\n",
    "if benchmark_results and not bench_summary_df.empty:\n",
    "print(\"\\n--- Visualizing Benchmark Optimization Results (Hybrid) ---\")\n",
    "# Filter for successful runs\n",
    "bench_success_df = bench_summary_df[bench_summary_df['Status'] == 'Success'].copy()\n",
    "if not bench_success_df.empty:\n",
    "bench_success_df['Best Value'].plot(kind='bar', figsize=(8, 5), color='skyblue')\n",
    "plt.title(\"Best Value Found per Benchmark Function (Hybrid)\")\n",
    "plt.ylabel(\"Best Value (Log Scale)\")\n",
    "plt.yscale('log')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "bench_success_df['Time (s)'].plot(kind='bar', figsize=(8, 5), color='lightgreen')\n",
    "plt.title(\"Computational Time per Benchmark Function (Hybrid)\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "else:\n",
    "print(\"No successful benchmark results to plot.\")\n",
    "# Ensure all steps from data loading to final evaluation are documented in markdown.\n",
    "# Explain the hybrid algorithm concept and your specific implementation choices (when implemented).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07e8f50",
   "metadata": {},
   "source": [
    "# # 13. Tools and Libraries\n",
    "#\n",
    "# The following libraries were used or are intended for use in this project:\n",
    "#\n",
    "# - **Pandas:** Data loading and manipulation.\n",
    "# - **NumPy:** Numerical operations, array handling.\n",
    "# - **Scikit-learn:** Data preprocessing, model training (Random Forest, SVM, MLP), evaluation metrics, train/test split, hyperparameter tuning.\n",
    "# - **Matplotlib & Seaborn:** Data visualization.\n",
    "# - **SciPy:** Scientific computing, used here for benchmark functions.\n",
    "# - **Requests & StringIO:** Fetching data from URLs.\n",
    "# - **Tqdm:** Progress bars.\n",
    "# - **PySwarm:** (Optional/Potential) A library for Particle Swarm Optimization. Could be a starting point for the PSO component or comparison. (Not directly used in the provided individual/hybrid code but listed in original `pip install`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eb3fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All necessary imports are listed at the beginning of the relevant sections.\n",
    "# Ensure your environment has these libraries installed:\n",
    "# pip install pandas numpy scikit-learn matplotlib seaborn scipy requests tqdm\n",
    "print(\"\\nRequired Libraries:\")\n",
    "print(\"- pandas\")\n",
    "print(\"- numpy\")\n",
    "print(\"- scikit-learn\")\n",
    "print(\"- matplotlib\")\n",
    "print(\"- seaborn\")\n",
    "print(\"- scipy\")\n",
    "print(\"- requests\")\n",
    "print(\"- io (built-in)\")\n",
    "print(\"- time (built-in)\")\n",
    "print(\"- sys (built-in)\")\n",
    "print(\"- tqdm\")\n",
    "# print(\"- pyswarm (Optional, for PSO component or comparison)\")\n",
    "print(\"\\nNotebook structure complete.\")\n",
    "print(\"Remember to replace the plausible hybrid implementations in Step 5 and Step 9\")\n",
    "print(\"with your specific novel algorithm if it differs.\")\n",
    "print(\"Step 11 requires implementing the configurable hybrid algorithm and running experiments.\")\n",
    "```"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
