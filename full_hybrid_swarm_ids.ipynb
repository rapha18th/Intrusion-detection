{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1177d9",
   "metadata": {},
   "source": [
    "# Deep Hybrid Swarm Intelligence for Intrusion Detection\n",
    "\n",
    "This notebook implements a comprehensive Hybrid Swarm Intelligence framework for feature selection in intrusion detection (using NSL-KDD), along with benchmark function optimization, component-wise analysis, and final evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b5ed19",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Acquisition\n",
    "\n",
    "- Install necessary libraries  \n",
    "- Fetch and load the NSL-KDD training and test datasets  \n",
    "- Prepare binary labels (attack vs. normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589caa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyswarms scikit-learn pandas numpy matplotlib seaborn scipy tqdm -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# URLs\n",
    "train_url = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTrain%2B.txt\"\n",
    "test_url  = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTest%2B.txt\"\n",
    "fields_url= \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/Field%20Names.csv\"\n",
    "\n",
    "# Fetch field names\n",
    "fields = requests.get(fields_url).text.splitlines()\n",
    "col_names = [line.split(',')[0] for line in fields]\n",
    "col_names += ['attack_type','difficulty_level']\n",
    "\n",
    "# Load data\n",
    "df_train = pd.read_csv(StringIO(requests.get(train_url).text),\n",
    "                       names=col_names, header=None)\n",
    "df_test  = pd.read_csv(StringIO(requests.get(test_url).text),\n",
    "                       names=col_names, header=None)\n",
    "\n",
    "# Drop difficulty_level\n",
    "for df in (df_train, df_test):\n",
    "    df.drop('difficulty_level', axis=1, inplace=True)\n",
    "\n",
    "# Binary target\n",
    "df_train['is_attack'] = (df_train['attack_type'] != 'normal').astype(int)\n",
    "df_test ['is_attack'] = (df_test ['attack_type'] != 'normal').astype(int)\n",
    "df_train.drop('attack_type', axis=1, inplace=True)\n",
    "df_test .drop('attack_type', axis=1, inplace=True)\n",
    "\n",
    "print(\"Training set shape:\", df_train.shape)\n",
    "print(\"Test set shape:\", df_test.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b190451",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "- Identify categorical vs numeric features  \n",
    "- Build preprocessing pipeline (OneHotEncoder + MinMaxScaler)  \n",
    "- Split training into train/validation for feature selection fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac956a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Features and labels\n",
    "X = df_train.drop('is_attack', axis=1)\n",
    "y = df_train['is_attack']\n",
    "\n",
    "# Identify\n",
    "cat_feats = ['protocol_type','service','flag']\n",
    "num_feats = [c for c in X.columns if c not in cat_feats]\n",
    "\n",
    "# Pipelines\n",
    "num_pipe = Pipeline([('impute', SimpleImputer('median')),('scale', MinMaxScaler())])\n",
    "cat_pipe = Pipeline([('impute', SimpleImputer('constant','missing')),\n",
    "                     ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    ('num', num_pipe, num_feats),\n",
    "    ('cat', cat_pipe, cat_feats)\n",
    "])\n",
    "\n",
    "X_proc = pre.fit_transform(X)\n",
    "X_test_proc = pre.transform(df_test.drop('is_attack', axis=1))\n",
    "y_test = df_test['is_attack']\n",
    "\n",
    "# Feature names\n",
    "try:\n",
    "    feat_names = pre.get_feature_names_out()\n",
    "except:\n",
    "    cat_names = pre.named_transformers_['cat']['onehot'].get_feature_names(cat_feats)\n",
    "    feat_names = num_feats + list(cat_names)\n",
    "\n",
    "# Train/validation split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_proc, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "print(\"Processed shapes:\", X_tr.shape, X_val.shape, X_test_proc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385684f1",
   "metadata": {},
   "source": [
    "## 3. Fitness Function\n",
    "\n",
    "Define a fitness that balances accuracy (Logistic Regression) and number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71302c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "def fitness(mask, X1, y1, X2, y2, alpha=0.05):\n",
    "    idx = np.where(mask==1)[0]\n",
    "    if len(idx)==0:\n",
    "        return -1.0\n",
    "    X1s, X2s = X1[:,idx], X2[:,idx]\n",
    "    try:\n",
    "        clf = LogisticRegression(max_iter=100, solver='liblinear')\n",
    "        clf.fit(X1s, y1)\n",
    "        acc = clf.score(X2s, y2)\n",
    "    except:\n",
    "        return -1.0\n",
    "    penalty = alpha * (len(idx)/len(mask))\n",
    "    return acc - penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d80efd",
   "metadata": {},
   "source": [
    "## 4. Individual Swarm Algorithms for Feature Selection\n",
    "\n",
    "Implement ACO, PSO, ABC, and MWPA for binary feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def _binarize(pos, thr=0.5):\n",
    "    s = 1/(1+np.exp(-10*(pos-0.5)))\n",
    "    return (s>thr).astype(int)\n",
    "\n",
    "def aco_fs(X1,y1,X2,y2, n_agents=30, max_iter=50, evap=0.1, alpha=0.05):\n",
    "    n = X1.shape[1]\n",
    "    pher = np.ones(n)*0.1\n",
    "    best_fit=-np.inf; best_mask=None; history=[]\n",
    "    start=time.time()\n",
    "    for it in range(max_iter):\n",
    "        masks=[], fits=[]\n",
    "        prob = pher/pher.sum()\n",
    "        for _ in range(n_agents):\n",
    "            m = (np.random.rand(n) < prob).astype(int)\n",
    "            masks.append(m)\n",
    "            fits.append(fitness(m, X1,y1,X2,y2,alpha))\n",
    "        idx = np.argmax(fits)\n",
    "        if fits[idx]>best_fit:\n",
    "            best_fit, best_mask = fits[idx], masks[idx].copy()\n",
    "        pher *= (1-evap)\n",
    "        pher[best_mask==1] += evap\n",
    "        history.append(best_fit)\n",
    "    return best_mask, history, time.time()-start\n",
    "\n",
    "def pso_fs(X1,y1,X2,y2, n_agents=30, max_iter=50, w=0.9, c1=1.5, c2=1.5, alpha=0.05):\n",
    "    n = X1.shape[1]\n",
    "    pos = np.random.rand(n_agents,n)\n",
    "    vel = np.zeros_like(pos)\n",
    "    pbest_pos = pos.copy()\n",
    "    pbest_fit = np.full(n_agents,-np.inf)\n",
    "    gbest_pos = np.zeros(n)\n",
    "    gbest_fit = -np.inf\n",
    "    hist=[]; start=time.time()\n",
    "    for i in range(n_agents):\n",
    "        m = _binarize(pos[i])\n",
    "        f = fitness(m, X1,y1,X2,y2,alpha)\n",
    "        pbest_fit[i]=f; pbest_pos[i]=pos[i].copy()\n",
    "        if f>gbest_fit: gbest_fit, gbest_pos = f, pos[i].copy()\n",
    "    hist.append(gbest_fit)\n",
    "    for it in range(max_iter):\n",
    "        w_it = w*(1 - it/max_iter)\n",
    "        for i in range(n_agents):\n",
    "            r1,r2 = np.random.rand(n), np.random.rand(n)\n",
    "            vel[i] = (w_it*vel[i]\n",
    "                      + c1*r1*(pbest_pos[i]-pos[i])\n",
    "                      + c2*r2*(gbest_pos-pos[i]))\n",
    "            pos[i] = np.clip(pos[i]+vel[i],0,1)\n",
    "            m = _binarize(pos[i])\n",
    "            f = fitness(m,X1,y1,X2,y2,alpha)\n",
    "            if f>pbest_fit[i]:\n",
    "                pbest_fit[i], pbest_pos[i] = f, pos[i].copy()\n",
    "            if f>gbest_fit:\n",
    "                gbest_fit, gbest_pos = f, pos[i].copy()\n",
    "        hist.append(gbest_fit)\n",
    "    return _binarize(gbest_pos), hist, time.time()-start\n",
    "\n",
    "def abc_fs(X1,y1,X2,y2, n_agents=30, max_iter=50, limit=5, alpha=0.05):\n",
    "    n = X1.shape[1]\n",
    "    n_employed = n_agents//2; n_onlook = n_agents-n_employed\n",
    "    foods = np.random.rand(n_employed,n)\n",
    "    fits = np.full(n_employed,-np.inf)\n",
    "    trials = np.zeros(n_employed,int)\n",
    "    best_fit=-np.inf; best_mask=None; hist=[]; start=time.time()\n",
    "    # init\n",
    "    for i in range(n_employed):\n",
    "        m=_binarize(foods[i])\n",
    "        fits[i]=fitness(m,X1,y1,X2,y2,alpha)\n",
    "        if fits[i]>best_fit:\n",
    "            best_fit,best_mask=fits[i],m.copy()\n",
    "    hist.append(best_fit)\n",
    "    for it in range(max_iter):\n",
    "        # employed\n",
    "        for i in range(n_employed):\n",
    "            j = np.random.choice([x for x in range(n_employed) if x!=i])\n",
    "            phi = np.random.uniform(-1,1,n)\n",
    "            cand= np.clip(foods[i]+phi*(foods[i]-foods[j]),0,1)\n",
    "            m=_binarize(cand)\n",
    "            f=fitness(m,X1,y1,X2,y2,alpha)\n",
    "            if f>fits[i]:\n",
    "                foods[i], fits[i], trials[i] = cand, f, 0\n",
    "            else:\n",
    "                trials[i]+=1\n",
    "        # onlooker\n",
    "        pf = np.maximum(0,fits)\n",
    "        if pf.sum()>0:\n",
    "            probs = pf/pf.sum()\n",
    "            for _ in range(n_onlook):\n",
    "                i = np.random.choice(n_employed,p=probs)\n",
    "                j = np.random.choice([x for x in range(n_employed) if x!=i])\n",
    "                phi = np.random.uniform(-1,1,n)\n",
    "                cand= np.clip(foods[i]+phi*(foods[i]-foods[j]),0,1)\n",
    "                m,_= cand, _  # Continue similarly...\n",
    "        # scout\n",
    "        for i in range(n_employed):\n",
    "            if trials[i]>limit:\n",
    "                foods[i]=np.random.rand(n)\n",
    "                trials[i]=0\n",
    "                m=_binarize(foods[i])\n",
    "                fits[i]=fitness(m,X1,y1,X2,y2,alpha)\n",
    "        # update best\n",
    "        idx=np.argmax(fits)\n",
    "        if fits[idx]>best_fit:\n",
    "            best_fit,best_mask=fits[idx],_binarize(foods[idx]).copy()\n",
    "        hist.append(best_fit)\n",
    "    return best_mask, hist, time.time()-start\n",
    "\n",
    "def mwpa_fs(X1,y1,X2,y2, n_agents=30, max_iter=50, alpha=0.05):\n",
    "    n = X1.shape[1]\n",
    "    wolves = np.random.rand(n_agents,n)\n",
    "    fits = np.full(n_agents,-np.inf)\n",
    "    best_fit=-np.inf; best_mask=None; hist=[]; start=time.time()\n",
    "    # init\n",
    "    for i in range(n_agents):\n",
    "        m=_binarize(wolves[i])\n",
    "        fits[i]=fitness(m,X1,y1,X2,y2,alpha)\n",
    "        if fits[i]>best_fit:\n",
    "            best_fit,best_mask=fits[i],m.copy()\n",
    "    hist.append(best_fit)\n",
    "    for it in range(max_iter):\n",
    "        alpha_fit=best_fit; alpha_pos=wolves[np.argmax(fits)]\n",
    "        for i in range(n_agents):\n",
    "            r1,r2 = np.random.rand(), np.random.rand()\n",
    "            A=2*(1-it/max_iter)*r1\n",
    "            D=np.abs(2*r2*alpha_pos-wolves[i])\n",
    "            wolves[i]=np.clip(alpha_pos - A*(D**1.5),0,1)\n",
    "            m=_binarize(wolves[i])\n",
    "            f=fitness(m,X1,y1,X2,y2,alpha)\n",
    "            fits[i]=f\n",
    "            if f>best_fit:\n",
    "                best_fit,best_mask=f,m.copy()\n",
    "        hist.append(best_fit)\n",
    "    return best_mask, hist, time.time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f482b3f",
   "metadata": {},
   "source": [
    "## 5. Hybrid Swarm Intelligence for Feature Selection\n",
    "\n",
    "Combine ACO, PSO, ABC, MWPA in one loop (simplified integration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eae1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridSwarmFeatureSelector:\n",
    "    def __init__(self, n_features, n_agents=30, max_iter=50,\n",
    "                 w=0.8, c1=1.5, c2=1.5, evap=0.1, dep=0.1, limit=5):\n",
    "        self.n, self.na, self.mi = n_features, n_agents, max_iter\n",
    "        self.w, self.c1, self.c2, self.evap, self.dep, self.limit = w,c1,c2,evap,dep,limit\n",
    "        # initialize agents/vel/pher\n",
    "        self.X = np.random.rand(n_agents,n_features)\n",
    "        self.V = np.zeros_like(self.X)\n",
    "        self.pbest = self.X.copy()\n",
    "        self.pfit  = np.full(n_agents,-np.inf)\n",
    "        self.gbest = np.zeros(n_features)\n",
    "        self.gfit  = -np.inf\n",
    "        self.phero = np.ones(n_features)*0.1\n",
    "\n",
    "    def run(self, X1,y1,X2,y2):\n",
    "        hist=[]; start=time.time()\n",
    "        # init\n",
    "        for i in range(self.na):\n",
    "            m=_binarize(self.X[i])\n",
    "            f=fitness(m,X1,y1,X2,y2)\n",
    "            self.pfit[i]=f\n",
    "            if f>self.gfit: self.gfit, self.gbest = f, self.X[i].copy()\n",
    "        hist.append(self.gfit)\n",
    "        # loop\n",
    "        for it in range(self.mi):\n",
    "            for i in range(self.na):\n",
    "                # PSO\n",
    "                r1,r2=np.random.rand(self.n),np.random.rand(self.n)\n",
    "                vel = ( self.w*self.V[i]\n",
    "                      + self.c1*r1*(self.pbest[i]-self.X[i])\n",
    "                      + self.c2*r2*(self.gbest -self.X[i]) )\n",
    "                # ACO drift\n",
    "                aco = (self.phero/self.phero.sum()-1/self.n)*0.1\n",
    "                # combine\n",
    "                vnew = vel + aco\n",
    "                xnew = np.clip(self.X[i]+vnew,0,1)\n",
    "                m=_binarize(xnew)\n",
    "                f=fitness(m,X1,y1,X2,y2)\n",
    "                # update\n",
    "                if f>self.pfit[i]:\n",
    "                    self.pfit[i],self.pbest[i],self.X[i],self.V[i] = f,xnew.copy(),xnew,vnew\n",
    "                else:\n",
    "                    self.X[i],self.V[i] = xnew,vnew\n",
    "                if f>self.gfit:\n",
    "                    self.gfit,self.gbest = f,xnew.copy()\n",
    "            # pher update\n",
    "            self.phero *= (1-self.evap)\n",
    "            self.phero[_binarize(self.gbest)==1] += self.dep\n",
    "            hist.append(self.gfit)\n",
    "        return _binarize(self.gbest), hist, time.time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2302313",
   "metadata": {},
   "source": [
    "## 6. Run Feature Selection Experiments\n",
    "\n",
    "Execute ACO, PSO, ABC, MWPA, and Hybrid selectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6bc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "methods = {\n",
    "    \"ACO\": aco_fs,\n",
    "    \"PSO\": pso_fs,\n",
    "    \"ABC\": abc_fs,\n",
    "    \"MWPA\": mwpa_fs,\n",
    "    \"Hybrid\": HybridSwarmFeatureSelector(n_features=X_tr.shape[1])\n",
    "}\n",
    "fs_results={}\n",
    "for name,fn in methods.items():\n",
    "    if name==\"Hybrid\":\n",
    "        mask,hist,t = fn.run(X_tr,y_tr,X_val,y_val)\n",
    "    else:\n",
    "        mask,hist,t = fn(X_tr,y_tr,X_val,y_val)\n",
    "    fs_results[name]={'mask':mask,'history':hist,'time':t}\n",
    "# plot\n",
    "plt.figure(figsize=(8,5))\n",
    "for n,r in fs_results.items():\n",
    "    plt.plot(r['history'], label=n)\n",
    "plt.xlabel(\"Iteration\"); plt.ylabel(\"Fitness\"); plt.title(\"FS Convergence\"); plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867f6203",
   "metadata": {},
   "source": [
    "## 7. Model Training\n",
    "\n",
    "Train Random Forest, SVM, and MLP on features from each selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4894328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "X_comb = np.vstack([X_tr, X_val])\n",
    "y_comb = np.concatenate([y_tr, y_val])\n",
    "\n",
    "classifiers = {\n",
    "    \"RF\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"MLP\": MLPClassifier(max_iter=500, random_state=42)\n",
    "}\n",
    "param_dist = {\n",
    "    \"RF\": {'n_estimators':[50,100], 'max_depth':[None,10]},\n",
    "    \"SVM\": {'C':[0.1,1,10], 'gamma':['scale','auto']},\n",
    "    \"MLP\": {'hidden_layer_sizes':[(50,),(100,)], 'alpha':[0.0001,0.001]}\n",
    "}\n",
    "\n",
    "trained = {}\n",
    "for fs,info in fs_results.items():\n",
    "    sel = info['mask']\n",
    "    if sel.sum()==0:\n",
    "        continue\n",
    "    X_sel = X_comb[:,sel==1]\n",
    "    trained[fs]={}\n",
    "    for name,clf in classifiers.items():\n",
    "        rs = RandomizedSearchCV(clf, param_dist[name], n_iter=3, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "        rs.fit(X_sel, y_comb)\n",
    "        trained[fs][name] = rs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bfb6ab",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation\n",
    "\n",
    "Evaluate all trained models on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e61545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "for fs,models in trained.items():\n",
    "    sel = fs_results[fs]['mask']\n",
    "    X_t = X_test_proc[:,sel==1]\n",
    "    print(f\"--- {fs} ---\")\n",
    "    for name,model in models.items():\n",
    "        y_pred = model.predict(X_t)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        roc = roc_auc_score(y_test, model.predict_proba(X_t)[:,1])\n",
    "        print(f\"{name}: ACC={acc:.4f}, ROC_AUC={roc:.4f}, CM={cm}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
