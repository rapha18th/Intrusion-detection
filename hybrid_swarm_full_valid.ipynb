{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2618a049",
   "metadata": {},
   "source": [
    "# Deep Hybrid Swarm Intelligence IDS\n",
    "\n",
    "This notebook implements a hybrid swarm intelligence feature selection method integrating ACO, PSO, ABC, and MWPA, along with benchmark optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21079bd6",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Acquisition\n",
    "\n",
    "- Install dependencies and fetch NSL-KDD dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2e7d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install pyswarms scikit-learn pandas numpy matplotlib seaborn scipy tqdm -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from io import StringIO\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# URLs\n",
    "data_url = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTrain%2B.txt\"\n",
    "test_url = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTest%2B.txt\"\n",
    "features_url = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/Field%20Names.csv\"\n",
    "\n",
    "# Fetch feature names\n",
    "try:\n",
    "    resp = requests.get(features_url); resp.raise_for_status()\n",
    "    features_df = pd.read_csv(StringIO(resp.text), header=None)\n",
    "    column_names = features_df[0].tolist()\n",
    "    column_names += ['attack_type','difficulty_level']\n",
    "except:\n",
    "    column_names = [ 'duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment',\n",
    "                     'urgent','hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted',\n",
    "                     'num_root','num_file_creations','num_shells','num_access_files','num_outbound_cmds',\n",
    "                     'is_host_login','is_guest_login','count','srv_count','serror_rate','srv_serror_rate',\n",
    "                     'rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate','srv_diff_host_rate',\n",
    "                     'dst_host_count','dst_host_srv_count','dst_host_same_srv_rate','dst_host_diff_srv_rate',\n",
    "                     'dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate',\n",
    "                     'dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate',\n",
    "                     'attack_type','difficulty_level']\n",
    "\n",
    "# Load datasets\n",
    "df_train = pd.read_csv(StringIO(requests.get(data_url).text), header=None, names=column_names)\n",
    "df_test = pd.read_csv(StringIO(requests.get(test_url).text), header=None, names=column_names)\n",
    "for df in [df_train, df_test]:\n",
    "    if 'difficulty_level' in df: df.drop('difficulty_level', axis=1, inplace=True)\n",
    "# Binary target\n",
    "df_train['is_attack'] = (df_train['attack_type']!='normal').astype(int)\n",
    "df_test['is_attack']  = (df_test['attack_type']!='normal').astype(int)\n",
    "df_train.drop('attack_type', axis=1, inplace=True)\n",
    "df_test.drop('attack_type', axis=1, inplace=True)\n",
    "\n",
    "print(\"Train shape:\", df_train.shape, \"Test shape:\", df_test.shape)\n",
    "print(df_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc7276a",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "- One-Hot encode categorical features.\n",
    "- Scale numerical features.\n",
    "- Split train into train/validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db153c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Prepare X/y\n",
    "X_train = df_train.drop('is_attack', axis=1); y_train = df_train['is_attack']\n",
    "X_test  = df_test.drop('is_attack', axis=1);  y_test  = df_test['is_attack']\n",
    "\n",
    "cat = ['protocol_type','service','flag']\n",
    "num = [c for c in X_train.columns if c not in cat]\n",
    "\n",
    "num_pipe = Pipeline([('imp', SimpleImputer('median')), ('scale', MinMaxScaler())])\n",
    "cat_pipe = Pipeline([('imp', SimpleImputer('constant','missing')), ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "pre = ColumnTransformer([('num',num_pipe,num),('cat',cat_pipe,cat)])\n",
    "X_train_p = pre.fit_transform(X_train)\n",
    "X_test_p  = pre.transform(X_test)\n",
    "\n",
    "# Feature names\n",
    "try:\n",
    "    processed_features = pre.get_feature_names_out()\n",
    "except:\n",
    "    cat_names = pre.named_transformers_['cat']['onehot'].get_feature_names(cat)\n",
    "    processed_features = list(num)+list(cat_names)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train_p, y_train, test_size=0.25, random_state=42, stratify=y_train)\n",
    "\n",
    "print(\"Processed shapes:\", X_tr.shape, X_val.shape, X_test_p.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dd6ad2",
   "metadata": {},
   "source": [
    "## 3. Define Fitness Function\n",
    "\n",
    "Logistic Regression-based fitness: Accuracy - Î±*(#features/total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0de5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "def feature_selection_fitness(mask, X_tr, y_tr, X_val, y_val, alpha=0.05):\n",
    "    idx = np.where(mask==1)[0]\n",
    "    if len(idx)==0: return -1.0\n",
    "    X1, X2 = X_tr[:,idx], X_val[:,idx]\n",
    "    try:\n",
    "        model = LogisticRegression(max_iter=100, solver='liblinear')\n",
    "        model.fit(X1,y_tr)\n",
    "        acc = model.score(X2,y_val)\n",
    "    except:\n",
    "        return -1.0\n",
    "    penalty = alpha*(len(idx)/len(mask))\n",
    "    return acc - penalty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b3234b",
   "metadata": {},
   "source": [
    "## 4. Individual Swarm Algorithms for Feature Selection\n",
    "ACO, PSO, ABC, MWPA implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dd80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def _binarize(pos,thr=0.5):\n",
    "    s=1/(1+np.exp(-10*(pos-0.5)))\n",
    "    return (s>thr).astype(int)\n",
    "\n",
    "def aco_feature_selection(X_tr,y_tr,X_val,y_val,n_agents=30,max_iter=50,evap=0.1,alpha=0.05):\n",
    "    n_feat = X_tr.shape[1]\n",
    "    pher = np.ones(n_feat)*0.1\n",
    "    best_fit=-np.inf; best_mask=None; history=[]\n",
    "    start=time.time()\n",
    "    for it in range(max_iter):\n",
    "        masks=[]; fits=[]\n",
    "        prob = pher/pher.sum()\n",
    "        for _ in range(n_agents):\n",
    "            m=(np.random.rand(n_feat)<prob).astype(int)\n",
    "            masks.append(m)\n",
    "            fits.append(feature_selection_fitness(m,X_tr,y_tr,X_val,y_val,alpha))\n",
    "        idx=np.argmax(fits)\n",
    "        if fits[idx]>best_fit:\n",
    "            best_fit=fits[idx]; best_mask=masks[idx].copy()\n",
    "        pher*=(1-evap)\n",
    "        pher[best_mask==1]+=evap\n",
    "        history.append(best_fit)\n",
    "    return best_mask,history,time.time()-start\n",
    "# [Add pso_feature_selection, abc_feature_selection, mwpa_feature_selection]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13265d11",
   "metadata": {},
   "source": [
    "## 5. Hybrid Swarm Intelligence for Feature Selection\n",
    "Placeholder class for hybrid algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HybridSwarmFeatureSelector:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "    def run(self, *args, **kwargs):\n",
    "        return [], [], 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d7655b",
   "metadata": {},
   "source": [
    "## 6. Run Feature Selection Experiments\n",
    "Compare individual vs. hybrid methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c40edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "methods = {\"ACO\": aco_feature_selection, \"Hybrid\": HybridSwarmFeatureSelector}\n",
    "results = {}\n",
    "for name, fn in methods.items():\n",
    "    if name==\"Hybrid\":\n",
    "        sel, hist, t = fn().run(X_tr,y_tr,X_val,y_val)\n",
    "    else:\n",
    "        sel, hist, t = fn(X_tr,y_tr,X_val,y_val)\n",
    "    results[name]={'mask':sel,'hist':hist,'time':t}\n",
    "import matplotlib.pyplot as plt\n",
    "for k in results:\n",
    "    plt.plot(results[k]['hist'],label=k)\n",
    "plt.legend(); plt.title(\"Convergence\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d0c16f",
   "metadata": {},
   "source": [
    "## 7. Model Training\n",
    "Train RF, SVM, MLP on features selected by each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e3848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [Implement model training loop as provided earlier]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf84493",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation\n",
    "Evaluate on test set; compute metrics and plot ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92376ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [Implement evaluation code as provided earlier]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa84a83",
   "metadata": {},
   "source": [
    "## 9. Benchmark Function Analysis\n",
    "Placeholder for continuous hybrid optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f349a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HybridSwarmOptimizer:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "    def run(self):\n",
    "        return [], np.inf, [], 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a62e7",
   "metadata": {},
   "source": [
    "## 10. Component-wise Analysis\n",
    "Outline experiments with varied hybrid configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b66b01",
   "metadata": {},
   "source": [
    "## 11. Presentation and Demonstration\n",
    "Generate final comparison plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14bd80f",
   "metadata": {},
   "source": [
    "## 12. Tools and Libraries\n",
    "- pandas, numpy, scikit-learn, matplotlib, seaborn, scipy, requests, tqdm"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
